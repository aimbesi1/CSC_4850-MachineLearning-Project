{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aimbesi1/CSC_4850-MachineLearning-Project/blob/main/ML_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PjGD5VGFVS-s"
      },
      "outputs": [],
      "source": [
        "# Default imports\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "# Specific imports\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the housing dataset from Kaggle: https://www.kaggle.com/datasets/mirbektoktogaraev/madrid-real-estate-market"
      ],
      "metadata": {
        "id": "89_ilQegV-MS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Manually download it and upload to this istance data sample space\n",
        "### Note DO NOT change these operations or all your answers will be incorrect\n",
        "\n",
        "### Let's do some transformations and extra features on this.\n",
        "df=pd.read_csv('houses_Madrid.csv', encoding='utf-8')"
      ],
      "metadata": {
        "id": "J_sakm7HV90A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select/clean features here\n",
        "\n",
        "# Do what needs to be done to the data so that the models can run"
      ],
      "metadata": {
        "id": "cQxCC0sziHIa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update X values later\n",
        "df_short = df.iloc[:1000, :][['sq_mt_built', 'rent_price', 'buy_price']].dropna()\n",
        "df_short['high_price'] = df_short['buy_price'].apply(lambda x: 1 if x > np.median(df_short['buy_price']) else 0)\n",
        "X = df_short[['sq_mt_built', 'rent_price']]\n",
        "# y = df_short[['buy_price']]\n",
        "y = df_short['high_price'].values\n",
        "\n"
      ],
      "metadata": {
        "id": "mv3OV1HJE4VZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "def init_models():\n",
        "  dt = DecisionTreeRegressor(random_state=1234)\n",
        "  perceptron = Perceptron(random_state=1234)\n",
        "  nb = GaussianNB()\n",
        "  log_reg = LogisticRegression(random_state=1234)\n",
        "  lin_reg = LinearRegression()\n",
        "  ridge = Ridge(alpha=0.5, fit_intercept=True, random_state=1234)\n",
        "  lasso = Lasso(alpha=0.1, fit_intercept=True, random_state=1234)\n",
        "  ef = ElasticNet(alpha=0.9, fit_intercept=True, random_state=1234)\n",
        "  svm_linear = svm.SVC(kernel=\"linear\", random_state=1234)\n",
        "  svm_rbf = svm.SVC(kernel=\"rbf\", random_state=1234)\n",
        "  gbr = GradientBoostingRegressor(random_state=1234)\n",
        "  mlp = MLPRegressor(random_state=1234)\n",
        "  svr_poly = svm.SVR(kernel=\"poly\")\n",
        "\n",
        "  dict = {\n",
        "      \"dt\": dt,\n",
        "      \"perceptron\": perceptron,\n",
        "      \"nb\": nb,\n",
        "      \"log_reg\": log_reg,\n",
        "      \"lin_reg\": lin_reg,\n",
        "      \"ridge\": ridge,\n",
        "      \"lasso\": lasso,\n",
        "      \"ef\": ef,\n",
        "      \"svm_linear\": svm_linear,\n",
        "      \"svm_rbf\": svm_rbf,\n",
        "      \"gbr\": gbr,\n",
        "      \"mlp\": mlp,\n",
        "      \"svr_poly\": svr_poly\n",
        "  }\n",
        "\n",
        "  return dict"
      ],
      "metadata": {
        "id": "vp82oe_ux2xM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_models(models, X_train, X_test, y_train, y_test, lc_dict, m_dict):\n",
        "  def get_metrics(model, X_train, y_train):\n",
        "    lc = learning_curve(estimator=model, X=X_train, y=y_train, cv=10, shuffle=True, random_state=1234)\n",
        "    cv = cross_validate(model, X_train, y_train, cv=10, return_train_score=True, return_estimator=True)\n",
        "    return lc, cv\n",
        "\n",
        "\n",
        "  for key in models.keys():\n",
        "    lc, cv = None, None\n",
        "    if key == \"lin_reg\":\n",
        "      X_train_scaled = StandardScaler().fit_transform(X_train)\n",
        "      X_test_scaled = StandardScaler().fit_transform(X_test)\n",
        "      lc, cv = get_metrics(models[key], X_train_scaled, y_train)\n",
        "    else:\n",
        "      lc, cv = get_metrics(models[key], X_train, y_train)\n",
        "    \n",
        "    lc_dict[key] = lc\n",
        "    m_dict[key] = cv\n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "# def run_models(models, X_train, y_train, X_test, y_test):\n",
        "\n",
        "#   # Decision Tree\n",
        "#   models[\"dt\"].fit(X_train, y_train)\n",
        "#   pred_Y1 = models[\"dt\"].predict(X_test)\n",
        "#   print(metrics.classification_report(y_test, pred_Y1))\n",
        "\n",
        "#   # SVM Linear\n",
        "#   f1_scaledX = StandardScaler().fit(X_train).transform(X_train)\n",
        "#   f1_scaledX_test = StandardScaler().fit(X_test).transform(X_test)\n",
        "\n",
        "#   models[\"svm_linear\"].fit(f1_scaledX, y_train)\n",
        "#   pred_Y1 = models[\"svm_linear\"].predict(f1_scaledX_test)\n",
        "#   print(metrics.classification_report(y_test, pred_Y1))\n",
        "\n",
        "#   sizes1, train_scores1, valid_scores1 = learning_curve(estimator = svm_linear, X = f1_scaledX_test, y=y_test, shuffle = True, random_state = 1234)\n",
        "\n",
        "#   # RBF\n",
        "#   models[\"svm_rbf\"].fit(X_train, y_train)\n",
        "#   pred_Y3 = models[\"svm_rbf\"].predict(X_test)\n",
        "#   print(metrics.classification_report(y_test, pred_Y3))\n",
        "\n",
        "#   sizes3, train_scores3, valid_scores3 = learning_curve(estimator = svm_rbf, X = X_test, y=y_test, shuffle = True, random_state = 1234)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "def show_learning_curve(ax, sizes, train_scores, valid_scores, title):\n",
        "  train_mean = train_scores.mean(axis=1)\n",
        "  valid_mean = valid_scores.mean(axis=0)\n",
        "  ax.plot(sizes, train_mean, label = \"Training Error\")\n",
        "  ax.plot(sizes, valid_mean, label = \"Validation Error\")\n",
        "  ax.legend()\n",
        "  ax.set_title(title)\n",
        "\n",
        "\n",
        "# # Learning curves\n",
        "# f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (15, 5), sharey=True)\n",
        "# show_learning_curve(ax1, sizes1, train_scores1, valid_scores1, \"Linear\")\n",
        "# show_learning_curve(ax2, sizes2, train_scores2, valid_scores2, \"Poly\")\n",
        "# show_learning_curve(ax3, sizes3, train_scores3, valid_scores3, \"RBF\")\n",
        "\n",
        "# acc_linear = metrics.accuracy_score(fold[\"y_test\"], pred_Y1)\n",
        "# acc_poly = metrics.accuracy_score(fold[\"y_test\"], pred_Y2)\n",
        "# acc_rbf = metrics.accuracy_score(fold[\"y_test\"], pred_Y3)\n",
        "# return {\"linear\": svm_linear, \"poly\": svm_poly, \"rbf\": svm_rbf}\n",
        "\n",
        "# f1_results = run_models(fold1, svm_linear, svm_poly, svm_rbf)"
      ],
      "metadata": {
        "id": "OlQED2C0kSQ-"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Pipeline\n",
        "\n",
        "''' \n",
        "For each sampling:\n",
        "  Set up the models\n",
        "  Initialize L: list of LCs (list of training scores + valid scores)\n",
        "  Initialize M: list of metrics (predicted Y)\n",
        "  \n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "def pipe(X, y):\n",
        "  train_sizes = [0.50, 0.70, 0.80]\n",
        "  # learning_curves and metrics are arrays of 3 dictionaries each.\n",
        "  # Each dictionary will hold the learning curve and metrics data for each model in each fold. \n",
        "  learning_curves = np.array([{}, {}, {}])\n",
        "  metrics = np.array([{}, {}, {}])\n",
        "  models = {}\n",
        "  best_models = np.array([{}, {}, {}])\n",
        "\n",
        "  for i in range(len(train_sizes)):\n",
        "    models = init_models()\n",
        "    rbf = {\"rbf\": models[\"svm_rbf\"]}\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_sizes[i], random_state=1234)\n",
        "\n",
        "    # Test with 1 model\n",
        "    run_models(rbf, X_train, X_test, y_train, y_test, learning_curves[i], metrics[i])\n",
        "      \n",
        "    \n",
        "    print(learning_curves[i])\n",
        "    \n",
        "    print(metrics[i])\n",
        "\n",
        "    # Stop at 1 loop for now\n",
        "    # break\n",
        "  \n",
        "  # Now pick the best estimators for each algorithm, for each sample size, and take the lc and metrics data:\n",
        "\n",
        "  # for i in range(len(train_sizes)):\n",
        "  #   for key in models.keys():\n",
        "  #     estimators = metrics[i][key]\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "# def pipe(X, y):\n",
        "#   train_sizes = [0.50, 0.70, 0.80]\n",
        "#   for size in train_sizes:\n",
        "#     models = init_models()\n",
        "#     rbf = models[\"svm_rbf\"]\n",
        "#     X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=size, random_state=1234)\n",
        "\n",
        "#     kfold = KFold(n_splits=10, random_state=1234, shuffle=True)\n",
        "\n",
        "#     for index, (train, test) in enumerate(kfold.split(X_train,y_train)):\n",
        "#       X_train_folds = X_train[train]\n",
        "#       y_train_folds = y_train[train]\n",
        "\n",
        "#       X_test_folds = X_train[test]\n",
        "#       y_test_folds = y_train[test]\n",
        "\n",
        "#       run_models(models, X_train_folds, y_train_folds, X_test_folds, y_test_folds)\n",
        "\n",
        "pipe(X, y)"
      ],
      "metadata": {
        "id": "OVEa6yRHpsVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "303e860b-8afe-4bfa-9e24-d93da40bbb7b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rbf': (array([ 45, 146, 247, 348, 450]), array([[0.95555556, 1.        , 0.95555556, 0.97777778, 0.95555556,\n",
            "        0.97777778, 0.95555556, 1.        , 0.95555556, 0.97777778],\n",
            "       [0.97945205, 0.99315068, 1.        , 1.        , 0.97260274,\n",
            "        0.98630137, 0.97260274, 0.97945205, 0.98630137, 0.97260274],\n",
            "       [0.99190283, 1.        , 0.99190283, 0.99595142, 0.98380567,\n",
            "        0.99595142, 0.9757085 , 0.98380567, 0.98785425, 0.97975709],\n",
            "       [0.98275862, 0.98563218, 0.99137931, 0.99425287, 0.98563218,\n",
            "        0.98850575, 0.98563218, 0.98563218, 0.98563218, 0.98850575],\n",
            "       [0.98444444, 0.98666667, 0.99555556, 0.98666667, 0.98666667,\n",
            "        0.99555556, 0.98888889, 0.98888889, 0.98444444, 0.98444444]]), array([[0.94, 1.  , 1.  , 0.96, 0.9 , 1.  , 0.96, 0.9 , 0.96, 1.  ],\n",
            "       [0.94, 1.  , 1.  , 0.98, 0.96, 1.  , 0.96, 0.9 , 0.98, 1.  ],\n",
            "       [1.  , 1.  , 1.  , 0.96, 0.98, 1.  , 0.96, 0.96, 0.98, 1.  ],\n",
            "       [0.98, 1.  , 1.  , 0.98, 0.98, 1.  , 0.96, 0.96, 1.  , 1.  ],\n",
            "       [1.  , 0.98, 1.  , 0.98, 0.98, 1.  , 0.96, 0.96, 1.  , 1.  ]]))}\n",
            "{'rbf': {'fit_time': array([0.00291348, 0.00282431, 0.00284266, 0.00285029, 0.00283504,\n",
            "       0.00335026, 0.00283217, 0.00274229, 0.00285149, 0.00279856]), 'score_time': array([0.00152206, 0.00137281, 0.00140047, 0.00140572, 0.00154996,\n",
            "       0.00145864, 0.00137234, 0.00135469, 0.00136471, 0.00139499]), 'estimator': [SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234)], 'test_score': array([1.  , 0.98, 1.  , 0.98, 0.98, 1.  , 0.96, 0.96, 1.  , 1.  ]), 'train_score': array([0.98444444, 0.98666667, 0.99555556, 0.98666667, 0.98666667,\n",
            "       0.99555556, 0.98888889, 0.98888889, 0.98444444, 0.98444444])}}\n",
            "{'rbf': (array([ 63, 204, 346, 488, 630]), array([[0.95238095, 0.96825397, 0.98412698, 0.96825397, 0.98412698,\n",
            "        0.96825397, 0.93650794, 1.        , 0.96825397, 0.98412698],\n",
            "       [0.97058824, 0.98039216, 0.98529412, 0.97058824, 0.99019608,\n",
            "        0.98039216, 0.98529412, 1.        , 0.99019608, 0.97058824],\n",
            "       [0.98554913, 0.97976879, 0.99132948, 0.97687861, 0.98554913,\n",
            "        0.97687861, 0.98265896, 0.98554913, 0.98265896, 0.97109827],\n",
            "       [0.9897541 , 0.98155738, 0.9897541 , 0.97540984, 0.9795082 ,\n",
            "        0.98360656, 0.98360656, 0.98360656, 0.98155738, 0.98360656],\n",
            "       [0.98730159, 0.98412698, 0.98730159, 0.98253968, 0.98412698,\n",
            "        0.98412698, 0.98412698, 0.98412698, 0.98253968, 0.98253968]]), array([[0.95714286, 0.97142857, 0.95714286, 0.94285714, 1.        ,\n",
            "        0.95714286, 0.98571429, 0.98571429, 0.91428571, 1.        ],\n",
            "       [0.97142857, 0.97142857, 0.95714286, 0.98571429, 1.        ,\n",
            "        0.98571429, 0.98571429, 0.98571429, 0.97142857, 1.        ],\n",
            "       [0.97142857, 0.97142857, 0.95714286, 0.98571429, 1.        ,\n",
            "        0.98571429, 0.98571429, 0.97142857, 0.95714286, 1.        ],\n",
            "       [0.97142857, 0.97142857, 0.95714286, 0.98571429, 1.        ,\n",
            "        0.98571429, 0.98571429, 0.98571429, 0.95714286, 1.        ],\n",
            "       [0.97142857, 0.98571429, 0.95714286, 1.        , 1.        ,\n",
            "        0.98571429, 0.98571429, 0.98571429, 0.97142857, 1.        ]]))}\n",
            "{'rbf': {'fit_time': array([0.00333571, 0.00341058, 0.00339603, 0.00349927, 0.00339127,\n",
            "       0.00335979, 0.0033989 , 0.00334311, 0.00338793, 0.00339556]), 'score_time': array([0.00146484, 0.00148296, 0.00147152, 0.00153112, 0.00146317,\n",
            "       0.00146651, 0.00149035, 0.00145936, 0.00150228, 0.00145745]), 'estimator': [SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234)], 'test_score': array([0.97142857, 0.98571429, 0.95714286, 1.        , 1.        ,\n",
            "       0.98571429, 0.98571429, 0.98571429, 0.97142857, 1.        ]), 'train_score': array([0.98730159, 0.98412698, 0.98730159, 0.98253968, 0.98412698,\n",
            "       0.98412698, 0.98412698, 0.98412698, 0.98253968, 0.98253968])}}\n",
            "{'rbf': (array([ 72, 234, 396, 558, 720]), array([[0.98611111, 0.97222222, 0.98611111, 0.95833333, 0.98611111,\n",
            "        0.98611111, 0.95833333, 1.        , 0.97222222, 0.95833333],\n",
            "       [0.98290598, 1.        , 0.97008547, 0.97435897, 0.97863248,\n",
            "        0.98717949, 0.97863248, 0.97863248, 0.97863248, 0.97435897],\n",
            "       [0.96717172, 0.98232323, 0.98989899, 0.98737374, 0.97979798,\n",
            "        0.99494949, 0.97474747, 0.97474747, 0.98484848, 0.97474747],\n",
            "       [0.98207885, 0.98566308, 0.9874552 , 0.98924731, 0.98566308,\n",
            "        0.98387097, 0.98207885, 0.98028674, 0.98924731, 0.98207885],\n",
            "       [0.98472222, 0.99027778, 0.99027778, 0.98472222, 0.98194444,\n",
            "        0.99305556, 0.98194444, 0.99305556, 0.98611111, 0.98333333]]), array([[0.925 , 0.9625, 0.9875, 0.95  , 0.9625, 0.9875, 0.9375, 0.975 ,\n",
            "        0.9125, 1.    ],\n",
            "       [0.9875, 0.9875, 0.9875, 0.95  , 0.975 , 1.    , 0.975 , 0.975 ,\n",
            "        0.9625, 1.    ],\n",
            "       [0.95  , 0.9625, 1.    , 0.9625, 0.975 , 1.    , 0.975 , 0.975 ,\n",
            "        0.975 , 1.    ],\n",
            "       [0.9875, 0.9625, 1.    , 0.9625, 1.    , 1.    , 0.975 , 0.9875,\n",
            "        0.975 , 1.    ],\n",
            "       [0.9875, 0.975 , 1.    , 0.9625, 1.    , 1.    , 0.975 , 0.9875,\n",
            "        0.975 , 1.    ]]))}\n",
            "{'rbf': {'fit_time': array([0.00380135, 0.0036447 , 0.00625539, 0.00713325, 0.00728273,\n",
            "       0.00730538, 0.00762749, 0.00706267, 0.00729322, 0.01075864]), 'score_time': array([0.00147438, 0.00149512, 0.00250483, 0.00261879, 0.00233293,\n",
            "       0.00273871, 0.00245214, 0.00227809, 0.00290728, 0.00246477]), 'estimator': [SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234)], 'test_score': array([0.9875, 0.975 , 1.    , 0.9625, 1.    , 1.    , 0.975 , 0.9875,\n",
            "       0.975 , 1.    ]), 'train_score': array([0.98472222, 0.99027778, 0.99027778, 0.98472222, 0.98194444,\n",
            "       0.99305556, 0.98194444, 0.99305556, 0.98611111, 0.98333333])}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(model):\n",
        "  pred_Y = model.predict(X_test)\n",
        "  acc = metrics.accuracy_score(y_test, pred_Y)\n",
        "  precision = metrics.precision_score(y_test, pred_Y)\n",
        "  recall = metrics.recall_score(y_test, pred_Y)\n",
        "  f1_score = metrics.f1_score(y_test, pred_Y)\n",
        "  rmse = np.sqrt(metrics.mean_squared_error(y_test, pred_Y))\n",
        "  return [acc, precision, recall, f1_score, rmse]\n",
        "\n",
        "# table = pd.DataFrame()\n",
        "# table[\"Metric\"] = [\"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"RMSE\"]\n",
        "# table[\"Linear - Fold 2\"] = get_metrics(best_linear)\n",
        "# table[\"Poly - Fold 2\"] = get_metrics(best_poly)\n",
        "# table[\"RBF - Fold 2\"] = get_metrics(best_rbf)\n",
        "\n",
        "# table.head()"
      ],
      "metadata": {
        "id": "7-wRvWY7mvJ4"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}