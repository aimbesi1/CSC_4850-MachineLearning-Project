{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aimbesi1/CSC_4850-MachineLearning-Project/blob/main/ML_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PjGD5VGFVS-s"
      },
      "outputs": [],
      "source": [
        "# Default imports\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "# Specific imports\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.pipeline import Pipeline, make_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the housing dataset from Kaggle: https://www.kaggle.com/datasets/mirbektoktogaraev/madrid-real-estate-market"
      ],
      "metadata": {
        "id": "89_ilQegV-MS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Manually download it and upload to this istance data sample space\n",
        "### Note DO NOT change these operations or all your answers will be incorrect\n",
        "\n",
        "### Let's do some transformations and extra features on this.\n",
        "df=pd.read_csv('houses_Madrid.csv', encoding='utf-8')"
      ],
      "metadata": {
        "id": "J_sakm7HV90A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select/clean features here\n",
        "df.describe()\n",
        "# Do what needs to be done to the data so that the models can run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "cQxCC0sziHIa",
        "outputId": "edc3ed3e-e3b3-4c6b-e360-c148f9c25191"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Unnamed: 0            id   sq_mt_built  sq_mt_useful       n_rooms  \\\n",
              "count  21742.000000  21742.000000  21616.000000   8228.000000  21742.000000   \n",
              "mean   10870.500000  10871.500000    146.920892    103.458192      3.005749   \n",
              "std     6276.519112   6276.519112    134.181865     88.259192      1.510497   \n",
              "min        0.000000      1.000000     13.000000      1.000000      0.000000   \n",
              "25%     5435.250000   5436.250000     70.000000     59.000000      2.000000   \n",
              "50%    10870.500000  10871.500000    100.000000     79.000000      3.000000   \n",
              "75%    16305.750000  16306.750000    162.000000    113.000000      4.000000   \n",
              "max    21741.000000  21742.000000    999.000000    998.000000     24.000000   \n",
              "\n",
              "        n_bathrooms     n_floors  sq_mt_allotment  latitude  longitude  ...  \\\n",
              "count  21726.000000  1437.000000      1432.000000       0.0        0.0  ...   \n",
              "mean       2.091687     3.128740       241.692737       NaN        NaN  ...   \n",
              "std        1.406992     0.907713       247.484853       NaN        NaN  ...   \n",
              "min        1.000000     1.000000         1.000000       NaN        NaN  ...   \n",
              "25%        1.000000     2.000000         2.000000       NaN        NaN  ...   \n",
              "50%        2.000000     3.000000       232.000000       NaN        NaN  ...   \n",
              "75%        2.000000     4.000000       354.000000       NaN        NaN  ...   \n",
              "max       16.000000     7.000000       997.000000       NaN        NaN  ...   \n",
              "\n",
              "       rent_price_by_area     buy_price  buy_price_by_area    built_year  \\\n",
              "count                 0.0  2.174200e+04       21742.000000  10000.000000   \n",
              "mean                  NaN  6.537356e+05        4020.523871   1970.046400   \n",
              "std                   NaN  7.820821e+05        1908.418774     69.386705   \n",
              "min                   NaN  3.600000e+04         447.000000   1723.000000   \n",
              "25%                   NaN  1.980000e+05        2551.000000   1957.000000   \n",
              "50%                   NaN  3.750000e+05        3720.000000   1970.000000   \n",
              "75%                   NaN  7.636000e+05        5000.000000   1994.000000   \n",
              "max                   NaN  8.800000e+06       18889.000000   8170.000000   \n",
              "\n",
              "       are_pets_allowed  is_furnished  is_kitchen_equipped  \\\n",
              "count               0.0           0.0                  0.0   \n",
              "mean                NaN           NaN                  NaN   \n",
              "std                 NaN           NaN                  NaN   \n",
              "min                 NaN           NaN                  NaN   \n",
              "25%                 NaN           NaN                  NaN   \n",
              "50%                 NaN           NaN                  NaN   \n",
              "75%                 NaN           NaN                  NaN   \n",
              "max                 NaN           NaN                  NaN   \n",
              "\n",
              "       has_private_parking  has_public_parking  parking_price  \n",
              "count                  0.0                 0.0    7719.000000  \n",
              "mean                   NaN                 NaN    2658.000518  \n",
              "std                    NaN                 NaN   13360.966258  \n",
              "min                    NaN                 NaN       0.000000  \n",
              "25%                    NaN                 NaN       0.000000  \n",
              "50%                    NaN                 NaN       0.000000  \n",
              "75%                    NaN                 NaN       0.000000  \n",
              "max                    NaN                 NaN  600000.000000  \n",
              "\n",
              "[8 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87f62fd9-0144-4e6f-a107-ff9e39bcb069\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>sq_mt_built</th>\n",
              "      <th>sq_mt_useful</th>\n",
              "      <th>n_rooms</th>\n",
              "      <th>n_bathrooms</th>\n",
              "      <th>n_floors</th>\n",
              "      <th>sq_mt_allotment</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>...</th>\n",
              "      <th>rent_price_by_area</th>\n",
              "      <th>buy_price</th>\n",
              "      <th>buy_price_by_area</th>\n",
              "      <th>built_year</th>\n",
              "      <th>are_pets_allowed</th>\n",
              "      <th>is_furnished</th>\n",
              "      <th>is_kitchen_equipped</th>\n",
              "      <th>has_private_parking</th>\n",
              "      <th>has_public_parking</th>\n",
              "      <th>parking_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>21742.000000</td>\n",
              "      <td>21742.000000</td>\n",
              "      <td>21616.000000</td>\n",
              "      <td>8228.000000</td>\n",
              "      <td>21742.000000</td>\n",
              "      <td>21726.000000</td>\n",
              "      <td>1437.000000</td>\n",
              "      <td>1432.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.174200e+04</td>\n",
              "      <td>21742.000000</td>\n",
              "      <td>10000.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7719.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>10870.500000</td>\n",
              "      <td>10871.500000</td>\n",
              "      <td>146.920892</td>\n",
              "      <td>103.458192</td>\n",
              "      <td>3.005749</td>\n",
              "      <td>2.091687</td>\n",
              "      <td>3.128740</td>\n",
              "      <td>241.692737</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.537356e+05</td>\n",
              "      <td>4020.523871</td>\n",
              "      <td>1970.046400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2658.000518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6276.519112</td>\n",
              "      <td>6276.519112</td>\n",
              "      <td>134.181865</td>\n",
              "      <td>88.259192</td>\n",
              "      <td>1.510497</td>\n",
              "      <td>1.406992</td>\n",
              "      <td>0.907713</td>\n",
              "      <td>247.484853</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.820821e+05</td>\n",
              "      <td>1908.418774</td>\n",
              "      <td>69.386705</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13360.966258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.600000e+04</td>\n",
              "      <td>447.000000</td>\n",
              "      <td>1723.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5435.250000</td>\n",
              "      <td>5436.250000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.980000e+05</td>\n",
              "      <td>2551.000000</td>\n",
              "      <td>1957.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>10870.500000</td>\n",
              "      <td>10871.500000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>232.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.750000e+05</td>\n",
              "      <td>3720.000000</td>\n",
              "      <td>1970.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>16305.750000</td>\n",
              "      <td>16306.750000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>354.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.636000e+05</td>\n",
              "      <td>5000.000000</td>\n",
              "      <td>1994.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>21741.000000</td>\n",
              "      <td>21742.000000</td>\n",
              "      <td>999.000000</td>\n",
              "      <td>998.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.800000e+06</td>\n",
              "      <td>18889.000000</td>\n",
              "      <td>8170.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>600000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87f62fd9-0144-4e6f-a107-ff9e39bcb069')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-87f62fd9-0144-4e6f-a107-ff9e39bcb069 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-87f62fd9-0144-4e6f-a107-ff9e39bcb069');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update X values later\n",
        "df_short = df.iloc[:4000, :][['sq_mt_built', 'rent_price', 'buy_price']].dropna()\n",
        "\n",
        "# df_short['high_price'] = df_short['buy_price'].apply(lambda x: 1 if x > np.median(df_short['buy_price']) else 0)\n",
        "X = df_short[['sq_mt_built', 'rent_price']]\n",
        "y = df_short['buy_price']\n",
        "# y = df_short['high_price'].values\n",
        "df_short.describe()\n",
        "\n"
      ],
      "metadata": {
        "id": "mv3OV1HJE4VZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "46b27f90-4ac9-4553-c4cd-989a05ec029d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       sq_mt_built    rent_price     buy_price\n",
              "count  4000.000000  4.000000e+03  4.000000e+03\n",
              "mean     98.567000 -8.281727e+03  2.997627e+05\n",
              "std      54.966729  5.470396e+05  3.118178e+05\n",
              "min      16.000000 -3.459028e+07  3.600000e+04\n",
              "25%      65.000000  7.250000e+02  1.490000e+05\n",
              "50%      85.000000  9.700000e+02  2.210000e+05\n",
              "75%     115.000000  1.218000e+03  3.232500e+05\n",
              "max     700.000000  2.517000e+03  8.800000e+06"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61a955c2-7d79-4160-83f1-c5541066a57b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sq_mt_built</th>\n",
              "      <th>rent_price</th>\n",
              "      <th>buy_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4000.000000</td>\n",
              "      <td>4.000000e+03</td>\n",
              "      <td>4.000000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>98.567000</td>\n",
              "      <td>-8.281727e+03</td>\n",
              "      <td>2.997627e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>54.966729</td>\n",
              "      <td>5.470396e+05</td>\n",
              "      <td>3.118178e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>16.000000</td>\n",
              "      <td>-3.459028e+07</td>\n",
              "      <td>3.600000e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>65.000000</td>\n",
              "      <td>7.250000e+02</td>\n",
              "      <td>1.490000e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>85.000000</td>\n",
              "      <td>9.700000e+02</td>\n",
              "      <td>2.210000e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>115.000000</td>\n",
              "      <td>1.218000e+03</td>\n",
              "      <td>3.232500e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>700.000000</td>\n",
              "      <td>2.517000e+03</td>\n",
              "      <td>8.800000e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61a955c2-7d79-4160-83f1-c5541066a57b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61a955c2-7d79-4160-83f1-c5541066a57b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61a955c2-7d79-4160-83f1-c5541066a57b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def discretize(y_subset, y, n):\n",
        "#   quantiles = []\n",
        "#   i = 0\n",
        "#   while i <= n:\n",
        "#     quantiles.append(y.quantile(i / n))\n",
        "#     i = i + 1\n",
        "#   return pd.cut(y_subset, bins=quantiles, labels=range(n))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.50, random_state=1234)\n",
        "\n",
        "y_train_d = pd.cut(y_train, bins=[0, y.quantile(0.25), y.quantile(0.5), y.quantile(0.75), y.quantile(1)], labels=[0, 1, 2, 3])\n",
        "y_test_d = pd.cut(y_test, bins=[0, y.quantile(0.25), y.quantile(0.5), y.quantile(0.75), y.quantile(1)], labels=[0, 1, 2, 3])\n",
        "\n",
        "y_train_d.loc[y_train_d.isna()].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysnoyoyVuwHT",
        "outputId": "24ac1561-3538-4bd8-b533-a61d695c1fcf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], Name: buy_price, dtype: category\n",
              "Categories (4, int64): [0 < 1 < 2 < 3])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "def init_models():\n",
        "  dt = DecisionTreeClassifier(random_state=1234)\n",
        "  perceptron = Perceptron(random_state=1234)\n",
        "  nb = GaussianNB()\n",
        "  log_reg = LogisticRegression(random_state=1234, solver='liblinear', multi_class='ovr', max_iter=150)\n",
        "  lin_reg = LinearRegression()\n",
        "  ridge = Ridge(alpha=0.5, fit_intercept=True, random_state=1234)\n",
        "  lasso = Lasso(alpha=0.1, fit_intercept=True, random_state=1234)\n",
        "  ef = ElasticNet(alpha=0.9, fit_intercept=True, random_state=1234)\n",
        "  svm_linear = make_pipeline(StandardScaler(), svm.SVC(kernel=\"linear\", random_state=1234))\n",
        "  svm_rbf = make_pipeline(StandardScaler(), svm.SVC(kernel=\"rbf\", random_state=1234))\n",
        "  gb = HistGradientBoostingClassifier(random_state=1234)\n",
        "  mlp = make_pipeline(StandardScaler(), MLPClassifier(solver='lbfgs', random_state=1234))\n",
        "  # svr_poly = svm.SVR(kernel=\"poly\")\n",
        "\n",
        "  c_dict = {\n",
        "      \"dt\": dt,\n",
        "      \"perceptron\": perceptron,\n",
        "      \"nb\": nb,\n",
        "      \"log_reg\": log_reg,\n",
        "      \"svm_linear\": svm_linear,\n",
        "      \"svm_rbf\": svm_rbf,\n",
        "      # \"gb\": gb,\n",
        "      # \"mlp\": mlp,\n",
        "  }\n",
        "\n",
        "  r_dict = {\n",
        "      \"lin_reg\": lin_reg,\n",
        "      \"ridge\": ridge,\n",
        "      \"lasso\": lasso,\n",
        "      \"ef\": ef,\n",
        "  }\n",
        "\n",
        "  return c_dict, r_dict"
      ],
      "metadata": {
        "id": "vp82oe_ux2xM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train Classifiers\n",
        "def train_classifier(models, X_train, X_test, y_train, y_test, lc_dict, m_dict, b_dict):\n",
        "  def get_metrics(model, X_train, y_train):\n",
        "    # lc = learning_curve(estimator=model, X=X_train, y=y_train, cv=10, shuffle=True, random_state=1234)\n",
        "    lc = -1\n",
        "    scorer = {\n",
        "        \"precision\": metrics.make_scorer(metrics.precision_score, average=\"micro\"),\n",
        "        \"recall\": metrics.make_scorer(metrics.precision_score, average=\"micro\"),\n",
        "        \"accuracy\": metrics.make_scorer(metrics.precision_score, average=\"micro\")\n",
        "    }\n",
        "    cv = cross_validate(model, X_train, y_train, cv=10, scoring=scorer, return_train_score=False, return_estimator=True)\n",
        "    best_score_index = cv[\"test_accuracy\"].argmax()\n",
        "    best = cv[\"estimator\"][best_score_index]\n",
        "    return lc, cv, best\n",
        "\n",
        "  for key in models.keys():\n",
        "    # if key in {\"svm_linear\", \"gb\", \"mlp\"}:\n",
        "    #   print(f\"Found key {key}, scaling data\")\n",
        "    #   X_train_scaled = StandardScaler().fit_transform(X_train)\n",
        "    #   X_test_scaled = StandardScaler().fit_transform(X_test)\n",
        "\n",
        "    #   models[key].fit(X_train_scaled, y_train)\n",
        "    #   # predY = models[key].predict(X_test_scaled)\n",
        "    #   lc, cv, best = get_metrics(models[key], X_train_scaled, y_train)\n",
        "    # else:\n",
        "    models[key].fit(X_train, y_train)\n",
        "    # predY = models[key].predict(X_test)\n",
        "    lc, cv, best = get_metrics(models[key], X_train, y_train)\n",
        "    \n",
        "    # lc_dict[key] = lc\n",
        "    m_dict[key] = cv\n",
        "    b_dict[key] = best\n",
        "\n",
        "# Test Classifiers\n",
        "def test_classifier(models, X_train, X_test, y_train, y_test, lc_dict, bp_dict):\n",
        "  for key in models.keys():\n",
        "  #   if key in {\"svm_linear\", \"gb\", \"mlp\"}:\n",
        "  #     print(f\"Found key {key}, scaling data\")\n",
        "  #     X_train_scaled = StandardScaler().fit_transform(X_train)\n",
        "  #     X_test_scaled = StandardScaler().fit_transform(X_test)\n",
        "\n",
        "  #     models[key].fit(X_train_scaled, y_train)\n",
        "  #     predY = models[key].predict(X_test_scaled)\n",
        "  #     lc = learning_curve(estimator=models[key], X=X_test, y=y_test, shuffle=True, random_state=1234)\n",
        "  #   else:\n",
        "    models[key].fit(X_train, y_train)\n",
        "    predY = models[key].predict(X_test)\n",
        "    lc = learning_curve(estimator=models[key], X=X_test, y=y_test, shuffle=True, random_state=1234)\n",
        "\n",
        "    lc_dict[key] = lc\n",
        "    bp_dict[key] = predY\n",
        "\n",
        "\n",
        "def train_regression(models, X_train, X_test, y_train, y_test, lc_dict, m_dict, b_dict):\n",
        "  def get_metrics(model, X_train, y_train):\n",
        "    # lc = learning_curve(estimator=model, X=X_train, y=y_train, cv=10, shuffle=True, random_state=1234)\n",
        "    lc = -1\n",
        "    cv = cross_validate(model, X_train, y_train, cv=10, return_train_score=False, return_estimator=True)\n",
        "    # best_score_index = cv[\"test_accuracy\"].argmax()\n",
        "    # best = cv[\"estimator\"][best_score_index]\n",
        "    best = None\n",
        "    return lc, cv, best\n",
        "\n",
        "\n",
        "  for key in models.keys():\n",
        "    lc, cv, best = None, None, None\n",
        "    if key in {\"svm_lin\", \"lin_reg\", \"ridge\", \"lasso\", \"ef\"}:\n",
        "      X_train_scaled = StandardScaler().fit_transform(X_train)\n",
        "      X_test_scaled = StandardScaler().fit_transform(X_test)\n",
        "\n",
        "      models[key].fit(X_train_scaled, y_train)\n",
        "      predY = models[key].predict(X_test_scaled)\n",
        "      lc, cv, best = get_metrics(models[key], X_train_scaled, y_train)\n",
        "    else:\n",
        "      models[key].fit(X_train, y_train)\n",
        "      predY = models[key].predict(X_test)\n",
        "      lc, cv, best = get_metrics(models[key], X_train, y_train)\n",
        "    \n",
        "    # lc_dict[key] = lc\n",
        "    m_dict[key] = cv\n",
        "    b_dict[key] = best\n",
        "\n",
        "def test_regression(models, X_train, X_test, y_train, y_test, lc_dict, bp_dict):\n",
        "  for key in models.keys():\n",
        "    lc, predY = None, None\n",
        "    if key in {\"svm_lin\", \"lin_reg\", \"ridge\", \"lasso\", \"ef\"}:\n",
        "      X_train_scaled = StandardScaler().fit_transform(X_train)\n",
        "      X_test_scaled = StandardScaler().fit_transform(X_test)\n",
        "\n",
        "      models[key].fit(X_train_scaled, y_train)\n",
        "      predY = models[key].predict(X_test_scaled)\n",
        "      lc = learning_curve(estimator=models[key], X=X_test_scaled, y=y_test, shuffle=True, random_state=1234)\n",
        "    else:\n",
        "      models[key].fit(X_train, y_train)\n",
        "      predY = models[key].predict(X_test)\n",
        "      lc = learning_curve(estimator=models[key], X=X_test, y=y_test, shuffle=True, random_state=1234)\n",
        "\n",
        "    lc_dict[key] = lc\n",
        "    bp_dict[key] = predY\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "# def run_models(models, X_train, y_train, X_test, y_test):\n",
        "\n",
        "#   # Decision Tree\n",
        "#   models[\"dt\"].fit(X_train, y_train)\n",
        "#   pred_Y1 = models[\"dt\"].predict(X_test)\n",
        "#   print(metrics.classification_report(y_test, pred_Y1))\n",
        "\n",
        "#   # SVM Linear\n",
        "#   f1_scaledX = StandardScaler().fit(X_train).transform(X_train)\n",
        "#   f1_scaledX_test = StandardScaler().fit(X_test).transform(X_test)\n",
        "\n",
        "#   models[\"svm_linear\"].fit(f1_scaledX, y_train)\n",
        "#   pred_Y1 = models[\"svm_linear\"].predict(f1_scaledX_test)\n",
        "#   print(metrics.classification_report(y_test, pred_Y1))\n",
        "\n",
        "#   sizes1, train_scores1, valid_scores1 = learning_curve(estimator = svm_linear, X = f1_scaledX_test, y=y_test, shuffle = True, random_state = 1234)\n",
        "\n",
        "#   # RBF\n",
        "#   models[\"svm_rbf\"].fit(X_train, y_train)\n",
        "#   pred_Y3 = models[\"svm_rbf\"].predict(X_test)\n",
        "#   print(metrics.classification_report(y_test, pred_Y3))\n",
        "\n",
        "#   sizes3, train_scores3, valid_scores3 = learning_curve(estimator = svm_rbf, X = X_test, y=y_test, shuffle = True, random_state = 1234)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "def show_learning_curve(ax, lc_sizes, train_scores, valid_scores, title):\n",
        "  train_mean = train_scores.mean(axis=1)\n",
        "  valid_mean = valid_scores.mean(axis=0)\n",
        "  ax.plot(lc_sizes, train_mean, label = \"Training Error\")\n",
        "  ax.plot(lc_sizes, valid_mean, label = \"Validation Error\")\n",
        "  ax.legend()\n",
        "  ax.set_title(title)\n",
        "\n",
        "\n",
        "# # Learning curves\n",
        "# f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (15, 5), sharey=True)\n",
        "# show_learning_curve(ax1, sizes1, train_scores1, valid_scores1, \"Linear\")\n",
        "# show_learning_curve(ax2, sizes2, train_scores2, valid_scores2, \"Poly\")\n",
        "# show_learning_curve(ax3, sizes3, train_scores3, valid_scores3, \"RBF\")\n",
        "\n",
        "# acc_linear = metrics.accuracy_score(fold[\"y_test\"], pred_Y1)\n",
        "# acc_poly = metrics.accuracy_score(fold[\"y_test\"], pred_Y2)\n",
        "# acc_rbf = metrics.accuracy_score(fold[\"y_test\"], pred_Y3)\n",
        "# return {\"linear\": svm_linear, \"poly\": svm_poly, \"rbf\": svm_rbf}\n",
        "\n",
        "# f1_results = run_models(fold1, svm_linear, svm_poly, svm_rbf)"
      ],
      "metadata": {
        "id": "OlQED2C0kSQ-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Pipeline\n",
        "\n",
        "''' \n",
        "For each sampling:\n",
        "  Set up the models\n",
        "  Initialize L: list of LCs (list of training scores + valid scores)\n",
        "  Initialize M: list of metrics (predicted Y)\n",
        "  \n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "def pipe(X, y):\n",
        "  train_sizes = [0.50, 0.70, 0.80]\n",
        "  # learning_curves and metrics are arrays of 3 dictionaries each.\n",
        "  # Each dictionary will hold the learning curve and metrics data for each model in each fold. \n",
        "  learning_curves = np.array([{}, {}, {}])\n",
        "  metrics = np.array([{}, {}, {}])\n",
        "  models = []\n",
        "  best_models = np.array([{}, {}, {}])\n",
        "  best_predictions = np.array([{}, {}, {}])\n",
        "\n",
        "  for i in range(len(train_sizes)):\n",
        "    models = init_models()\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_sizes[i], random_state=1234)\n",
        "\n",
        "    y_train_d = pd.cut(y_train, bins=[0, y.quantile(0.25), y.quantile(0.5), y.quantile(0.75), y.quantile(1)], labels=[0, 1, 2, 3])\n",
        "    y_test_d = pd.cut(y_test, bins=[0, y.quantile(0.25), y.quantile(0.5), y.quantile(0.75), y.quantile(1)], labels=[0, 1, 2, 3])\n",
        "\n",
        "    # y_train_d.describe()\n",
        "\n",
        "\n",
        "    # Test with 1 model\n",
        "    train_classifier(models[0], X_train, X_test, y_train_d, y_test_d, learning_curves[i], metrics[i], best_models[i])\n",
        "    # train_regression(models[1], X_train, X_test, y_train, y_test, learning_curves[i], metrics[i], best_models[i])\n",
        "    \n",
        "    \n",
        "    # print(learning_curves[i])\n",
        "    print(f\"Metrics for sample {i}:\")\n",
        "    print(metrics[i])\n",
        "\n",
        "    print(f\"Best model in sample {i}:\")\n",
        "    print(best_models[i])\n",
        "\n",
        "    # Stop at 1 loop with break\n",
        "    # break\n",
        "\n",
        "    # Now train the best models on the whole training set\n",
        "    \n",
        "    test_classifier(models[0], X_train, X_test, y_train_d, y_test_d, learning_curves[i], best_predictions[i])\n",
        "    # test_regression(models[1], X_train, X_test, y_train, y_test, learning_curves[i], best_predictions[i])\n",
        "\n",
        "    print(f\"Best prediction data for sample {i}:\")\n",
        "    print(best_predictions[i])\n",
        "\n",
        "    \n",
        "  \n",
        "  # Learning curves\n",
        "    f, ax = plt.subplots(1, len(models[0]), figsize = (15, 5), sharey=True)\n",
        "\n",
        "    for key in models[0]:\n",
        "      for j in range(3):\n",
        "        show_learning_curve(ax[i], learning_curves[i])\n",
        "      # break\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "# def pipe(X, y):\n",
        "#   train_sizes = [0.50, 0.70, 0.80]\n",
        "#   for size in train_sizes:\n",
        "#     models = init_models()\n",
        "#     rbf = models[\"svm_rbf\"]\n",
        "#     X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=size, random_state=1234)\n",
        "\n",
        "#     kfold = KFold(n_splits=10, random_state=1234, shuffle=True)\n",
        "\n",
        "#     for index, (train, test) in enumerate(kfold.split(X_train,y_train)):\n",
        "#       X_train_folds = X_train[train]\n",
        "#       y_train_folds = y_train[train]\n",
        "\n",
        "#       X_test_folds = X_train[test]\n",
        "#       y_test_folds = y_train[test]\n",
        "\n",
        "#       run_models(models, X_train_folds, y_train_folds, X_test_folds, y_test_folds)\n",
        "\n",
        "pipe(X, y)"
      ],
      "metadata": {
        "id": "OVEa6yRHpsVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a5924dd-2382-4609-be49-8ad3882f3a8d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for sample 0:\n",
            "{'dt': {'fit_time': array([0.00368977, 0.00351858, 0.00386477, 0.00397587, 0.00381041,\n",
            "       0.00743055, 0.00677347, 0.00520825, 0.00595069, 0.00422287]), 'score_time': array([0.00626826, 0.00747538, 0.00742221, 0.00630283, 0.01278186,\n",
            "       0.00765061, 0.00700617, 0.01114917, 0.01181936, 0.00656366]), 'estimator': [DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234)], 'test_precision': array([0.995, 0.995, 0.99 , 1.   , 1.   , 0.995, 0.995, 0.995, 1.   ,\n",
            "       1.   ]), 'test_recall': array([0.995, 0.995, 0.99 , 1.   , 1.   , 0.995, 0.995, 0.995, 1.   ,\n",
            "       1.   ]), 'test_accuracy': array([0.995, 0.995, 0.99 , 1.   , 1.   , 0.995, 0.995, 0.995, 1.   ,\n",
            "       1.   ])}, 'perceptron': {'fit_time': array([0.00880766, 0.00860715, 0.00839543, 0.00858331, 0.00933456,\n",
            "       0.01035953, 0.01030159, 0.01068521, 0.00869942, 0.02905488]), 'score_time': array([0.00699973, 0.00731897, 0.00894451, 0.00675035, 0.01095295,\n",
            "       0.00711942, 0.01023626, 0.00826097, 0.00700426, 0.01294374]), 'estimator': [Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234)], 'test_precision': array([0.255, 0.255, 0.255, 0.26 , 0.28 , 0.26 , 0.275, 0.26 , 0.22 ,\n",
            "       0.25 ]), 'test_recall': array([0.255, 0.255, 0.255, 0.26 , 0.28 , 0.26 , 0.275, 0.26 , 0.22 ,\n",
            "       0.25 ]), 'test_accuracy': array([0.255, 0.255, 0.255, 0.26 , 0.28 , 0.26 , 0.275, 0.26 , 0.22 ,\n",
            "       0.25 ])}, 'nb': {'fit_time': array([0.00356269, 0.00314808, 0.00330472, 0.00369573, 0.00328922,\n",
            "       0.00320053, 0.00350475, 0.00408912, 0.00343466, 0.00347257]), 'score_time': array([0.00667667, 0.00713587, 0.00671268, 0.0071311 , 0.00724602,\n",
            "       0.0065136 , 0.00690269, 0.00688004, 0.00702381, 0.00684977]), 'estimator': [GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB()], 'test_precision': array([0.875, 0.875, 0.895, 0.875, 0.91 , 0.895, 0.885, 0.885, 0.895,\n",
            "       0.89 ]), 'test_recall': array([0.875, 0.875, 0.895, 0.875, 0.91 , 0.895, 0.885, 0.885, 0.895,\n",
            "       0.89 ]), 'test_accuracy': array([0.875, 0.875, 0.895, 0.875, 0.91 , 0.895, 0.885, 0.885, 0.895,\n",
            "       0.89 ])}, 'log_reg': {'fit_time': array([0.01768136, 0.02196765, 0.02043247, 0.0253973 , 0.05064392,\n",
            "       0.02382898, 0.05416131, 0.02111411, 0.01847506, 0.0329175 ]), 'score_time': array([0.0075779 , 0.00741768, 0.00735855, 0.00752878, 0.00809932,\n",
            "       0.01068664, 0.00861454, 0.01078629, 0.00733948, 0.00696206]), 'estimator': [LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear')], 'test_precision': array([0.265, 0.265, 0.265, 0.265, 0.275, 0.265, 0.24 , 0.26 , 0.535,\n",
            "       0.26 ]), 'test_recall': array([0.265, 0.265, 0.265, 0.265, 0.275, 0.265, 0.24 , 0.26 , 0.535,\n",
            "       0.26 ]), 'test_accuracy': array([0.265, 0.265, 0.265, 0.265, 0.275, 0.265, 0.24 , 0.26 , 0.535,\n",
            "       0.26 ])}, 'svm_linear': {'fit_time': array([0.08303928, 0.09436941, 0.08418036, 0.08278561, 0.07768679,\n",
            "       0.07621908, 0.07594371, 0.07559085, 0.0783174 , 0.0810461 ]), 'score_time': array([0.01487708, 0.01442337, 0.01604271, 0.01442027, 0.0155201 ,\n",
            "       0.01437545, 0.01491952, 0.01521659, 0.02223063, 0.01508117]), 'estimator': [Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))])], 'test_precision': array([0.495, 0.545, 0.52 , 0.505, 0.535, 0.555, 0.565, 0.53 , 0.555,\n",
            "       0.515]), 'test_recall': array([0.495, 0.545, 0.52 , 0.505, 0.535, 0.555, 0.565, 0.53 , 0.555,\n",
            "       0.515]), 'test_accuracy': array([0.495, 0.545, 0.52 , 0.505, 0.535, 0.555, 0.565, 0.53 , 0.555,\n",
            "       0.515])}, 'svm_rbf': {'fit_time': array([0.12832618, 0.11721492, 0.12217283, 0.12664413, 0.11890817,\n",
            "       0.12041783, 0.12608171, 0.13041568, 0.11622047, 0.12491155]), 'score_time': array([0.02236342, 0.02312827, 0.0244112 , 0.02288961, 0.02235413,\n",
            "       0.02327442, 0.02312303, 0.02276206, 0.02297902, 0.02346992]), 'estimator': [Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))])], 'test_precision': array([0.47 , 0.535, 0.53 , 0.51 , 0.555, 0.53 , 0.56 , 0.51 , 0.53 ,\n",
            "       0.52 ]), 'test_recall': array([0.47 , 0.535, 0.53 , 0.51 , 0.555, 0.53 , 0.56 , 0.51 , 0.53 ,\n",
            "       0.52 ]), 'test_accuracy': array([0.47 , 0.535, 0.53 , 0.51 , 0.555, 0.53 , 0.56 , 0.51 , 0.53 ,\n",
            "       0.52 ])}}\n",
            "Best model in sample 0:\n",
            "{'dt': DecisionTreeClassifier(random_state=1234), 'perceptron': Perceptron(random_state=1234), 'nb': GaussianNB(), 'log_reg': LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), 'svm_linear': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), 'svm_rbf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best prediction data for sample 0:\n",
            "{'dt': array([1, 1, 2, ..., 3, 2, 0]), 'perceptron': array([1, 3, 3, ..., 3, 3, 3]), 'nb': array([1, 0, 2, ..., 3, 2, 0]), 'log_reg': array([0, 0, 0, ..., 0, 0, 0]), 'svm_linear': array([0, 0, 2, ..., 2, 2, 0]), 'svm_rbf': array([0, 0, 2, ..., 2, 2, 0])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for sample 1:\n",
            "{'dt': {'fit_time': array([0.00418878, 0.00436234, 0.00432658, 0.00420046, 0.00413394,\n",
            "       0.00389385, 0.00394177, 0.00391221, 0.00400138, 0.00382853]), 'score_time': array([0.00685954, 0.00671649, 0.00774741, 0.00907063, 0.00656533,\n",
            "       0.00681305, 0.00649381, 0.00652242, 0.00646067, 0.00696635]), 'estimator': [DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234)], 'test_precision': array([0.99642857, 0.99642857, 1.        , 0.99642857, 0.99285714,\n",
            "       1.        , 1.        , 0.99642857, 0.99642857, 1.        ]), 'test_recall': array([0.99642857, 0.99642857, 1.        , 0.99642857, 0.99285714,\n",
            "       1.        , 1.        , 0.99642857, 0.99642857, 1.        ]), 'test_accuracy': array([0.99642857, 0.99642857, 1.        , 0.99642857, 0.99285714,\n",
            "       1.        , 1.        , 0.99642857, 0.99642857, 1.        ])}, 'perceptron': {'fit_time': array([0.00901914, 0.01387572, 0.0280056 , 0.02943516, 0.03246617,\n",
            "       0.00943351, 0.02858734, 0.02729821, 0.03345871, 0.01030493]), 'score_time': array([0.00671077, 0.00925398, 0.00681353, 0.00923109, 0.0069623 ,\n",
            "       0.00679922, 0.00679731, 0.0068357 , 0.00702405, 0.01000357]), 'estimator': [Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234)], 'test_precision': array([0.25      , 0.26428571, 0.25714286, 0.25      , 0.26428571,\n",
            "       0.27857143, 0.26428571, 0.26785714, 0.26785714, 0.22857143]), 'test_recall': array([0.25      , 0.26428571, 0.25714286, 0.25      , 0.26428571,\n",
            "       0.27857143, 0.26428571, 0.26785714, 0.26785714, 0.22857143]), 'test_accuracy': array([0.25      , 0.26428571, 0.25714286, 0.25      , 0.26428571,\n",
            "       0.27857143, 0.26428571, 0.26785714, 0.26785714, 0.22857143])}, 'nb': {'fit_time': array([0.00322962, 0.00310183, 0.00318074, 0.00322628, 0.00330591,\n",
            "       0.00323534, 0.0031147 , 0.00322628, 0.00323653, 0.00346327]), 'score_time': array([0.00666881, 0.00667429, 0.00675464, 0.0068984 , 0.00677109,\n",
            "       0.00649762, 0.00695419, 0.00706053, 0.00668788, 0.00699639]), 'estimator': [GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB()], 'test_precision': array([0.88928571, 0.89642857, 0.88571429, 0.85714286, 0.91071429,\n",
            "       0.87857143, 0.91071429, 0.89285714, 0.86785714, 0.91428571]), 'test_recall': array([0.88928571, 0.89642857, 0.88571429, 0.85714286, 0.91071429,\n",
            "       0.87857143, 0.91071429, 0.89285714, 0.86785714, 0.91428571]), 'test_accuracy': array([0.88928571, 0.89642857, 0.88571429, 0.85714286, 0.91071429,\n",
            "       0.87857143, 0.91071429, 0.89285714, 0.86785714, 0.91428571])}, 'log_reg': {'fit_time': array([0.05227876, 0.06975913, 0.07141018, 0.0654614 , 0.05858779,\n",
            "       0.02738452, 0.03111625, 0.10949421, 0.03024864, 0.02023959]), 'score_time': array([0.00710654, 0.00867677, 0.00770426, 0.00690746, 0.00849438,\n",
            "       0.0071435 , 0.01138902, 0.01121759, 0.00708675, 0.00712967]), 'estimator': [LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear')], 'test_precision': array([0.24642857, 0.27857143, 0.26785714, 0.25714286, 0.24285714,\n",
            "       0.25714286, 0.27857143, 0.36785714, 0.26071429, 0.50714286]), 'test_recall': array([0.24642857, 0.27857143, 0.26785714, 0.25714286, 0.24285714,\n",
            "       0.25714286, 0.27857143, 0.36785714, 0.26071429, 0.50714286]), 'test_accuracy': array([0.24642857, 0.27857143, 0.26785714, 0.25714286, 0.24285714,\n",
            "       0.25714286, 0.27857143, 0.36785714, 0.26071429, 0.50714286])}, 'svm_linear': {'fit_time': array([0.15402031, 0.14510465, 0.1445601 , 0.14443231, 0.14303231,\n",
            "       0.15286303, 0.15907669, 0.14576197, 0.14490461, 0.14755416]), 'score_time': array([0.02158952, 0.0223639 , 0.02196813, 0.02120948, 0.02901244,\n",
            "       0.02154064, 0.02149606, 0.02110291, 0.02147651, 0.02136517]), 'estimator': [Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))])], 'test_precision': array([0.52857143, 0.51071429, 0.50357143, 0.51785714, 0.54642857,\n",
            "       0.53214286, 0.53571429, 0.56071429, 0.52857143, 0.56785714]), 'test_recall': array([0.52857143, 0.51071429, 0.50357143, 0.51785714, 0.54642857,\n",
            "       0.53214286, 0.53571429, 0.56071429, 0.52857143, 0.56785714]), 'test_accuracy': array([0.52857143, 0.51071429, 0.50357143, 0.51785714, 0.54642857,\n",
            "       0.53214286, 0.53571429, 0.56071429, 0.52857143, 0.56785714])}, 'svm_rbf': {'fit_time': array([0.23772621, 0.23146868, 0.2306571 , 0.22669601, 0.23566437,\n",
            "       0.23088074, 0.23261309, 0.23986697, 0.22607946, 0.23179245]), 'score_time': array([0.03662801, 0.03658342, 0.04150367, 0.03861976, 0.03735614,\n",
            "       0.03974724, 0.03666139, 0.03696799, 0.03751111, 0.03670001]), 'estimator': [Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))])], 'test_precision': array([0.51785714, 0.51071429, 0.50357143, 0.51071429, 0.52142857,\n",
            "       0.525     , 0.54285714, 0.54642857, 0.50714286, 0.575     ]), 'test_recall': array([0.51785714, 0.51071429, 0.50357143, 0.51071429, 0.52142857,\n",
            "       0.525     , 0.54285714, 0.54642857, 0.50714286, 0.575     ]), 'test_accuracy': array([0.51785714, 0.51071429, 0.50357143, 0.51071429, 0.52142857,\n",
            "       0.525     , 0.54285714, 0.54642857, 0.50714286, 0.575     ])}}\n",
            "Best model in sample 1:\n",
            "{'dt': DecisionTreeClassifier(random_state=1234), 'perceptron': Perceptron(random_state=1234), 'nb': GaussianNB(), 'log_reg': LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), 'svm_linear': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), 'svm_rbf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))])}\n",
            "Best prediction data for sample 1:\n",
            "{'dt': array([1, 1, 2, ..., 3, 3, 1]), 'perceptron': array([1, 1, 1, ..., 3, 1, 1]), 'nb': array([1, 0, 2, ..., 3, 3, 1]), 'log_reg': array([2, 2, 3, ..., 3, 3, 2]), 'svm_linear': array([0, 0, 2, ..., 3, 3, 2]), 'svm_rbf': array([0, 0, 2, ..., 3, 3, 2])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for sample 2:\n",
            "{'dt': {'fit_time': array([0.00425029, 0.00408435, 0.0043962 , 0.00420713, 0.00409412,\n",
            "       0.00452447, 0.00451612, 0.00452042, 0.00439525, 0.00443244]), 'score_time': array([0.00663424, 0.00649786, 0.00661135, 0.00639606, 0.00723648,\n",
            "       0.00735664, 0.00721955, 0.00716853, 0.00718498, 0.00734973]), 'estimator': [DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234), DecisionTreeClassifier(random_state=1234)], 'test_precision': array([0.996875, 1.      , 0.99375 , 1.      , 0.996875, 0.996875,\n",
            "       1.      , 0.996875, 0.996875, 1.      ]), 'test_recall': array([0.996875, 1.      , 0.99375 , 1.      , 0.996875, 0.996875,\n",
            "       1.      , 0.996875, 0.996875, 1.      ]), 'test_accuracy': array([0.996875, 1.      , 0.99375 , 1.      , 0.996875, 0.996875,\n",
            "       1.      , 0.996875, 0.996875, 1.      ])}, 'perceptron': {'fit_time': array([0.06583261, 0.04050112, 0.06647611, 0.06172037, 0.04373717,\n",
            "       0.06166196, 0.0696938 , 0.06727624, 0.08355784, 0.01094675]), 'score_time': array([0.00773072, 0.00716329, 0.00715089, 0.00771427, 0.00826621,\n",
            "       0.00694203, 0.00723362, 0.00810099, 0.00712562, 0.00729752]), 'estimator': [Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234), Perceptron(random_state=1234)], 'test_precision': array([0.259375, 0.253125, 0.2625  , 0.25    , 0.2625  , 0.26875 ,\n",
            "       0.2875  , 0.26875 , 0.259375, 0.259375]), 'test_recall': array([0.259375, 0.253125, 0.2625  , 0.25    , 0.2625  , 0.26875 ,\n",
            "       0.2875  , 0.26875 , 0.259375, 0.259375]), 'test_accuracy': array([0.259375, 0.253125, 0.2625  , 0.25    , 0.2625  , 0.26875 ,\n",
            "       0.2875  , 0.26875 , 0.259375, 0.259375])}, 'nb': {'fit_time': array([0.00339103, 0.00341845, 0.00354266, 0.0032835 , 0.00355649,\n",
            "       0.00346851, 0.00345922, 0.00363898, 0.00370216, 0.00348353]), 'score_time': array([0.00699139, 0.00690627, 0.00730968, 0.00733089, 0.00890517,\n",
            "       0.00716782, 0.00690269, 0.0076251 , 0.00725555, 0.00725412]), 'estimator': [GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB(), GaussianNB()], 'test_precision': array([0.9125  , 0.903125, 0.896875, 0.878125, 0.878125, 0.884375,\n",
            "       0.90625 , 0.89375 , 0.878125, 0.915625]), 'test_recall': array([0.9125  , 0.903125, 0.896875, 0.878125, 0.878125, 0.884375,\n",
            "       0.90625 , 0.89375 , 0.878125, 0.915625]), 'test_accuracy': array([0.9125  , 0.903125, 0.896875, 0.878125, 0.878125, 0.884375,\n",
            "       0.90625 , 0.89375 , 0.878125, 0.915625])}, 'log_reg': {'fit_time': array([0.06512475, 0.04222608, 0.12206531, 0.1173842 , 0.08552766,\n",
            "       0.03327131, 0.06305337, 0.10629582, 0.07208967, 0.026335  ]), 'score_time': array([0.00735617, 0.01170516, 0.0086937 , 0.00872731, 0.0098443 ,\n",
            "       0.00802159, 0.00775599, 0.00967288, 0.00809479, 0.00784469]), 'estimator': [LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear')], 'test_precision': array([0.34375 , 0.328125, 0.33125 , 0.365625, 0.39375 , 0.25625 ,\n",
            "       0.321875, 0.315625, 0.35625 , 0.490625]), 'test_recall': array([0.34375 , 0.328125, 0.33125 , 0.365625, 0.39375 , 0.25625 ,\n",
            "       0.321875, 0.315625, 0.35625 , 0.490625]), 'test_accuracy': array([0.34375 , 0.328125, 0.33125 , 0.365625, 0.39375 , 0.25625 ,\n",
            "       0.321875, 0.315625, 0.35625 , 0.490625])}, 'svm_linear': {'fit_time': array([0.19986558, 0.18898845, 0.21148515, 0.19106698, 0.19627976,\n",
            "       0.19450426, 0.18952179, 0.19996715, 0.18949032, 0.23989916]), 'score_time': array([0.02705216, 0.02658153, 0.02637625, 0.02742076, 0.02728438,\n",
            "       0.02661872, 0.02556252, 0.02605271, 0.02548862, 0.02567649]), 'estimator': [Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))])], 'test_precision': array([0.521875, 0.55    , 0.51875 , 0.509375, 0.528125, 0.5     ,\n",
            "       0.55    , 0.534375, 0.540625, 0.559375]), 'test_recall': array([0.521875, 0.55    , 0.51875 , 0.509375, 0.528125, 0.5     ,\n",
            "       0.55    , 0.534375, 0.540625, 0.559375]), 'test_accuracy': array([0.521875, 0.55    , 0.51875 , 0.509375, 0.528125, 0.5     ,\n",
            "       0.55    , 0.534375, 0.540625, 0.559375])}, 'svm_rbf': {'fit_time': array([0.30350637, 0.30151176, 0.30888534, 0.29800749, 0.29671431,\n",
            "       0.31158233, 0.30219579, 0.29365778, 0.30898166, 0.28614068]), 'score_time': array([0.04556274, 0.04658031, 0.04511929, 0.05075526, 0.04646397,\n",
            "       0.04628778, 0.0451231 , 0.04632974, 0.04553509, 0.04529381]), 'estimator': [Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))]), Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))])], 'test_precision': array([0.50625 , 0.521875, 0.515625, 0.509375, 0.509375, 0.50625 ,\n",
            "       0.55625 , 0.540625, 0.515625, 0.565625]), 'test_recall': array([0.50625 , 0.521875, 0.515625, 0.509375, 0.509375, 0.50625 ,\n",
            "       0.55625 , 0.540625, 0.515625, 0.565625]), 'test_accuracy': array([0.50625 , 0.521875, 0.515625, 0.509375, 0.509375, 0.50625 ,\n",
            "       0.55625 , 0.540625, 0.515625, 0.565625])}}\n",
            "Best model in sample 2:\n",
            "{'dt': DecisionTreeClassifier(random_state=1234), 'perceptron': Perceptron(random_state=1234), 'nb': GaussianNB(), 'log_reg': LogisticRegression(max_iter=150, multi_class='ovr', random_state=1234,\n",
            "                   solver='liblinear'), 'svm_linear': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(kernel='linear', random_state=1234))]), 'svm_rbf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
            "                ('svc', SVC(random_state=1234))])}\n",
            "Best prediction data for sample 2:\n",
            "{'dt': array([1, 1, 2, 1, 2, 3, 0, 3, 0, 1, 2, 2, 0, 3, 1, 2, 3, 3, 1, 0, 3, 2,\n",
            "       1, 1, 3, 0, 1, 2, 2, 2, 1, 1, 2, 1, 3, 0, 2, 2, 0, 1, 1, 0, 3, 2,\n",
            "       0, 2, 0, 2, 3, 3, 2, 1, 2, 1, 3, 0, 0, 0, 3, 2, 0, 0, 1, 2, 0, 2,\n",
            "       1, 0, 3, 1, 3, 1, 3, 1, 1, 2, 2, 2, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1,\n",
            "       3, 2, 1, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 0, 1, 3, 1, 0, 3, 1,\n",
            "       1, 2, 2, 2, 3, 3, 0, 0, 2, 3, 3, 0, 2, 3, 1, 2, 3, 0, 2, 3, 1, 0,\n",
            "       3, 2, 3, 0, 0, 2, 0, 2, 2, 0, 0, 1, 2, 0, 3, 1, 2, 2, 3, 2, 1, 2,\n",
            "       2, 3, 3, 0, 2, 1, 3, 2, 0, 1, 0, 3, 0, 0, 0, 3, 3, 2, 3, 0, 1, 2,\n",
            "       0, 0, 3, 3, 0, 1, 3, 0, 1, 2, 2, 2, 2, 0, 3, 3, 1, 3, 2, 1, 3, 2,\n",
            "       1, 2, 3, 0, 2, 3, 2, 1, 0, 1, 0, 1, 2, 1, 1, 0, 0, 1, 0, 2, 3, 2,\n",
            "       0, 2, 0, 0, 1, 0, 1, 3, 0, 3, 3, 3, 0, 3, 2, 3, 1, 1, 1, 2, 0, 0,\n",
            "       1, 3, 3, 2, 1, 0, 0, 2, 0, 0, 2, 2, 2, 0, 2, 1, 0, 0, 2, 0, 3, 0,\n",
            "       3, 1, 0, 1, 1, 0, 1, 3, 2, 1, 0, 3, 1, 2, 3, 1, 0, 3, 3, 0, 1, 0,\n",
            "       2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 3, 0,\n",
            "       1, 3, 2, 2, 1, 0, 0, 3, 0, 1, 3, 2, 1, 3, 0, 2, 1, 2, 1, 2, 2, 1,\n",
            "       1, 1, 0, 1, 2, 2, 0, 0, 2, 2, 3, 0, 3, 1, 3, 0, 2, 2, 1, 1, 0, 3,\n",
            "       2, 0, 3, 2, 1, 1, 2, 1, 0, 3, 0, 3, 3, 0, 2, 1, 3, 3, 0, 3, 1, 2,\n",
            "       1, 0, 2, 0, 3, 1, 2, 1, 3, 2, 1, 0, 2, 3, 0, 0, 1, 1, 3, 2, 2, 0,\n",
            "       3, 0, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 0, 3, 1, 2, 3, 3, 3, 0, 2,\n",
            "       0, 1, 1, 3, 2, 3, 1, 2, 0, 1, 2, 2, 0, 2, 0, 2, 0, 2, 0, 1, 2, 2,\n",
            "       0, 3, 3, 1, 0, 0, 3, 0, 0, 3, 1, 2, 1, 3, 1, 1, 2, 2, 2, 1, 2, 3,\n",
            "       2, 0, 3, 3, 3, 2, 2, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 3, 1,\n",
            "       1, 2, 2, 0, 2, 2, 1, 0, 2, 1, 0, 2, 3, 0, 0, 3, 0, 0, 2, 2, 3, 1,\n",
            "       0, 1, 1, 3, 0, 0, 0, 1, 1, 2, 1, 0, 2, 0, 1, 3, 2, 1, 3, 3, 1, 3,\n",
            "       3, 1, 1, 1, 2, 3, 2, 2, 3, 1, 0, 1, 1, 0, 0, 2, 3, 2, 0, 0, 2, 2,\n",
            "       0, 3, 1, 0, 3, 1, 1, 3, 2, 2, 0, 0, 2, 3, 2, 2, 2, 0, 0, 3, 1, 1,\n",
            "       1, 1, 3, 0, 1, 1, 1, 1, 3, 1, 3, 1, 3, 1, 0, 1, 2, 3, 0, 3, 3, 0,\n",
            "       2, 1, 2, 1, 3, 0, 3, 2, 3, 1, 2, 1, 2, 2, 0, 1, 1, 2, 3, 3, 2, 1,\n",
            "       0, 2, 0, 1, 1, 0, 1, 3, 2, 1, 2, 2, 1, 0, 1, 2, 0, 0, 3, 0, 1, 2,\n",
            "       3, 3, 3, 2, 2, 2, 3, 3, 2, 3, 0, 1, 0, 0, 0, 3, 3, 1, 1, 3, 0, 3,\n",
            "       2, 1, 3, 0, 2, 0, 3, 3, 2, 1, 1, 2, 1, 1, 3, 3, 3, 0, 1, 1, 2, 0,\n",
            "       1, 3, 3, 1, 3, 0, 3, 0, 3, 2, 3, 1, 1, 0, 1, 0, 1, 1, 0, 2, 1, 0,\n",
            "       0, 1, 0, 1, 3, 2, 2, 2, 0, 1, 1, 3, 3, 1, 3, 2, 3, 2, 1, 2, 1, 3,\n",
            "       1, 1, 2, 2, 1, 2, 3, 0, 0, 0, 2, 3, 3, 0, 2, 2, 0, 2, 1, 2, 3, 1,\n",
            "       0, 0, 3, 1, 2, 3, 2, 1, 1, 3, 1, 2, 0, 2, 1, 3, 3, 0, 2, 3, 1, 1,\n",
            "       3, 3, 0, 0, 1, 1, 1, 3, 2, 0, 2, 3, 1, 0, 1, 0, 3, 3, 0, 2, 0, 1,\n",
            "       3, 0, 2, 0, 2, 1, 3, 3]), 'perceptron': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0]), 'nb': array([1, 0, 2, 1, 2, 3, 0, 2, 0, 1, 2, 2, 0, 2, 1, 2, 3, 2, 1, 0, 3, 2,\n",
            "       1, 1, 3, 0, 1, 2, 2, 2, 1, 1, 2, 1, 3, 0, 2, 2, 0, 1, 1, 0, 2, 2,\n",
            "       0, 2, 0, 2, 3, 2, 2, 1, 2, 1, 2, 0, 0, 0, 2, 2, 0, 0, 1, 2, 0, 2,\n",
            "       1, 0, 3, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1,\n",
            "       2, 2, 1, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 0, 1, 3, 1, 0, 3, 1,\n",
            "       1, 2, 2, 2, 3, 2, 0, 0, 2, 3, 3, 0, 2, 2, 1, 2, 2, 0, 2, 3, 1, 0,\n",
            "       3, 2, 3, 0, 0, 2, 0, 2, 2, 0, 0, 1, 2, 0, 2, 1, 2, 2, 2, 2, 1, 2,\n",
            "       2, 2, 3, 0, 2, 1, 3, 2, 0, 1, 0, 3, 0, 1, 1, 3, 3, 2, 3, 0, 1, 2,\n",
            "       0, 0, 2, 2, 0, 1, 3, 0, 0, 2, 2, 2, 2, 0, 3, 3, 1, 3, 2, 1, 3, 2,\n",
            "       1, 2, 3, 0, 2, 2, 2, 1, 0, 1, 0, 1, 2, 1, 1, 0, 0, 1, 0, 2, 3, 2,\n",
            "       0, 2, 0, 0, 1, 0, 1, 3, 0, 2, 2, 3, 0, 3, 2, 3, 1, 1, 1, 2, 0, 0,\n",
            "       1, 3, 2, 2, 1, 0, 0, 2, 0, 0, 2, 2, 2, 0, 2, 1, 0, 0, 2, 0, 3, 0,\n",
            "       3, 1, 0, 1, 1, 0, 1, 3, 2, 1, 0, 3, 1, 2, 2, 1, 0, 2, 3, 0, 1, 0,\n",
            "       2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 2, 0,\n",
            "       1, 3, 2, 2, 1, 0, 0, 2, 0, 1, 2, 2, 2, 3, 0, 2, 1, 2, 0, 2, 2, 1,\n",
            "       1, 0, 0, 1, 2, 2, 0, 0, 2, 2, 3, 0, 3, 0, 3, 0, 2, 2, 1, 1, 0, 3,\n",
            "       2, 0, 3, 2, 1, 1, 2, 1, 0, 2, 0, 2, 3, 0, 2, 1, 3, 2, 0, 3, 1, 2,\n",
            "       1, 0, 2, 0, 3, 1, 2, 1, 3, 2, 1, 0, 2, 3, 0, 0, 1, 1, 3, 2, 2, 0,\n",
            "       3, 0, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 0, 3, 1, 2, 3, 2, 3, 0, 2,\n",
            "       0, 1, 1, 3, 2, 3, 1, 2, 0, 1, 2, 2, 0, 2, 0, 2, 0, 2, 0, 0, 2, 2,\n",
            "       0, 3, 3, 1, 0, 0, 2, 0, 0, 2, 1, 2, 2, 3, 1, 1, 2, 2, 2, 1, 2, 2,\n",
            "       2, 0, 2, 3, 3, 2, 2, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 3, 1,\n",
            "       1, 2, 2, 0, 2, 2, 1, 0, 2, 1, 0, 2, 3, 0, 0, 3, 0, 0, 2, 2, 2, 1,\n",
            "       0, 1, 0, 2, 0, 0, 0, 1, 1, 2, 1, 0, 2, 0, 1, 3, 2, 1, 3, 3, 0, 2,\n",
            "       3, 1, 1, 1, 2, 2, 2, 2, 2, 1, 0, 0, 1, 0, 0, 2, 3, 2, 0, 0, 2, 2,\n",
            "       0, 2, 0, 0, 3, 1, 1, 2, 2, 2, 0, 0, 2, 3, 2, 2, 2, 1, 0, 3, 1, 1,\n",
            "       1, 1, 2, 0, 1, 1, 1, 1, 2, 1, 3, 1, 3, 1, 0, 1, 2, 2, 0, 3, 3, 0,\n",
            "       2, 2, 2, 1, 2, 0, 2, 2, 3, 2, 2, 1, 2, 2, 1, 1, 1, 2, 3, 3, 2, 1,\n",
            "       0, 2, 0, 1, 1, 0, 1, 2, 2, 1, 2, 2, 0, 0, 1, 2, 0, 0, 3, 0, 1, 2,\n",
            "       3, 2, 3, 2, 2, 2, 2, 2, 2, 3, 0, 1, 0, 0, 0, 3, 2, 1, 1, 3, 0, 3,\n",
            "       2, 1, 3, 0, 2, 0, 3, 3, 2, 1, 1, 2, 1, 1, 2, 3, 3, 0, 1, 1, 2, 0,\n",
            "       1, 2, 2, 1, 2, 0, 3, 0, 3, 2, 3, 1, 1, 0, 1, 0, 1, 1, 0, 2, 1, 0,\n",
            "       0, 1, 0, 1, 3, 2, 2, 2, 0, 1, 1, 3, 3, 1, 3, 2, 2, 2, 1, 2, 1, 3,\n",
            "       1, 1, 2, 2, 2, 2, 3, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 3, 1,\n",
            "       0, 0, 3, 1, 2, 3, 2, 1, 1, 2, 2, 2, 0, 2, 1, 2, 3, 0, 2, 3, 1, 1,\n",
            "       3, 3, 0, 0, 1, 1, 1, 3, 2, 0, 2, 2, 1, 0, 1, 0, 2, 3, 0, 2, 0, 1,\n",
            "       3, 0, 2, 0, 2, 1, 3, 2]), 'log_reg': array([0, 0, 3, 0, 0, 3, 0, 3, 3, 0, 0, 3, 3, 3, 3, 2, 2, 3, 0, 0, 3, 2,\n",
            "       0, 3, 3, 0, 0, 3, 3, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 1, 3, 3,\n",
            "       3, 2, 0, 0, 3, 2, 2, 0, 2, 0, 2, 0, 0, 0, 3, 0, 1, 0, 1, 3, 0, 2,\n",
            "       0, 0, 3, 0, 3, 1, 3, 0, 0, 0, 3, 3, 2, 0, 0, 0, 3, 3, 3, 1, 0, 0,\n",
            "       3, 2, 0, 3, 0, 2, 3, 3, 3, 3, 3, 2, 3, 2, 2, 0, 1, 3, 0, 0, 3, 0,\n",
            "       0, 3, 3, 2, 3, 3, 0, 0, 3, 3, 3, 0, 2, 3, 3, 3, 3, 0, 0, 3, 3, 0,\n",
            "       3, 3, 3, 0, 0, 2, 0, 2, 3, 0, 0, 3, 2, 0, 3, 2, 2, 0, 3, 3, 3, 3,\n",
            "       0, 0, 3, 0, 0, 3, 3, 3, 0, 0, 0, 3, 0, 3, 3, 3, 2, 3, 3, 0, 3, 0,\n",
            "       0, 0, 2, 3, 0, 3, 3, 0, 0, 3, 3, 0, 3, 1, 3, 3, 0, 3, 2, 0, 3, 0,\n",
            "       3, 3, 3, 0, 3, 2, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 2,\n",
            "       0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0,\n",
            "       0, 3, 3, 3, 1, 0, 0, 0, 3, 0, 3, 0, 3, 3, 3, 0, 0, 0, 2, 0, 3, 0,\n",
            "       3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 2, 0, 3, 3, 1, 0, 3, 3, 0, 0, 0,\n",
            "       2, 0, 3, 0, 3, 3, 0, 3, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1, 3, 0, 0,\n",
            "       3, 3, 3, 0, 0, 0, 0, 3, 1, 3, 2, 0, 3, 3, 0, 0, 0, 0, 0, 2, 3, 0,\n",
            "       0, 0, 0, 0, 3, 3, 0, 0, 3, 3, 3, 0, 3, 0, 3, 0, 0, 0, 0, 3, 0, 3,\n",
            "       3, 0, 3, 2, 0, 0, 3, 0, 0, 2, 0, 3, 3, 0, 3, 3, 2, 3, 0, 2, 3, 3,\n",
            "       0, 0, 3, 0, 3, 2, 3, 0, 3, 3, 1, 0, 3, 2, 0, 0, 3, 0, 3, 0, 3, 0,\n",
            "       3, 0, 2, 3, 3, 0, 0, 0, 2, 3, 3, 0, 0, 0, 3, 0, 0, 3, 3, 3, 0, 3,\n",
            "       0, 3, 0, 3, 3, 2, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 3,\n",
            "       0, 3, 3, 0, 3, 0, 3, 0, 0, 0, 0, 0, 3, 3, 3, 2, 3, 3, 0, 3, 0, 3,\n",
            "       3, 0, 0, 3, 2, 3, 0, 0, 2, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0,\n",
            "       3, 2, 3, 0, 3, 0, 0, 3, 3, 0, 1, 2, 3, 0, 0, 3, 0, 0, 0, 2, 3, 3,\n",
            "       0, 0, 0, 2, 0, 0, 0, 2, 0, 3, 0, 0, 3, 0, 0, 3, 2, 0, 3, 3, 0, 3,\n",
            "       3, 0, 3, 0, 3, 3, 2, 3, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 3, 3,\n",
            "       0, 2, 0, 0, 3, 1, 0, 3, 3, 3, 0, 0, 0, 3, 0, 0, 3, 3, 0, 3, 0, 3,\n",
            "       1, 0, 2, 0, 0, 3, 3, 0, 3, 0, 3, 3, 3, 3, 0, 3, 2, 2, 0, 3, 2, 0,\n",
            "       2, 3, 2, 1, 2, 0, 3, 0, 3, 3, 0, 0, 0, 0, 3, 0, 0, 0, 2, 3, 3, 1,\n",
            "       1, 2, 0, 3, 2, 0, 0, 3, 3, 0, 0, 0, 0, 3, 3, 2, 3, 0, 3, 0, 3, 0,\n",
            "       3, 2, 3, 3, 0, 2, 3, 2, 0, 3, 0, 0, 0, 0, 0, 3, 3, 0, 0, 3, 0, 3,\n",
            "       3, 0, 3, 0, 2, 0, 3, 3, 0, 3, 0, 3, 0, 0, 0, 3, 3, 0, 3, 2, 3, 0,\n",
            "       0, 0, 0, 0, 3, 0, 3, 0, 3, 3, 3, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0,\n",
            "       0, 0, 0, 0, 3, 0, 2, 3, 0, 0, 0, 2, 3, 0, 3, 3, 3, 3, 0, 0, 0, 3,\n",
            "       0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 3, 3, 3, 3, 3, 0, 0, 3, 0, 2, 3, 0,\n",
            "       0, 0, 0, 0, 0, 3, 3, 3, 0, 3, 3, 0, 0, 3, 0, 3, 3, 0, 2, 3, 3, 0,\n",
            "       3, 3, 0, 0, 3, 0, 0, 3, 3, 0, 3, 3, 3, 0, 0, 0, 3, 3, 0, 3, 0, 3,\n",
            "       3, 0, 3, 0, 0, 3, 3, 2]), 'svm_linear': array([0, 0, 2, 0, 0, 3, 0, 3, 2, 0, 0, 3, 2, 2, 2, 0, 2, 2, 0, 0, 3, 2,\n",
            "       0, 2, 3, 0, 0, 2, 2, 0, 0, 0, 2, 0, 3, 0, 0, 0, 0, 0, 0, 2, 3, 2,\n",
            "       2, 2, 0, 0, 3, 0, 1, 0, 2, 0, 2, 0, 0, 0, 3, 0, 1, 0, 2, 3, 0, 2,\n",
            "       0, 0, 3, 0, 3, 2, 2, 0, 0, 0, 2, 3, 2, 0, 0, 0, 2, 2, 2, 1, 0, 0,\n",
            "       3, 1, 0, 3, 0, 2, 3, 2, 3, 2, 3, 2, 2, 1, 2, 0, 2, 3, 0, 0, 3, 0,\n",
            "       0, 2, 3, 1, 3, 2, 0, 0, 2, 3, 3, 0, 2, 2, 2, 2, 2, 0, 0, 3, 2, 0,\n",
            "       3, 2, 3, 0, 0, 1, 0, 2, 2, 0, 0, 2, 2, 1, 3, 2, 1, 0, 3, 2, 2, 2,\n",
            "       0, 0, 3, 0, 0, 2, 2, 3, 0, 0, 0, 3, 0, 2, 2, 3, 2, 2, 2, 0, 2, 0,\n",
            "       0, 0, 2, 3, 0, 2, 3, 0, 0, 2, 3, 0, 2, 2, 3, 3, 0, 3, 2, 0, 3, 0,\n",
            "       2, 2, 3, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 1,\n",
            "       0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 3, 2, 3, 2, 0, 2, 2, 2, 0,\n",
            "       0, 3, 2, 2, 2, 0, 0, 0, 2, 0, 3, 0, 2, 2, 2, 1, 0, 0, 2, 0, 2, 0,\n",
            "       3, 0, 0, 0, 0, 0, 0, 3, 3, 2, 0, 2, 0, 2, 2, 2, 0, 3, 3, 0, 0, 0,\n",
            "       2, 0, 2, 0, 3, 2, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0,\n",
            "       2, 3, 3, 0, 0, 0, 0, 3, 2, 2, 2, 0, 2, 3, 0, 0, 0, 0, 0, 0, 3, 0,\n",
            "       0, 0, 0, 0, 3, 2, 0, 1, 2, 3, 3, 0, 3, 0, 3, 0, 0, 1, 0, 2, 1, 3,\n",
            "       2, 0, 3, 1, 0, 0, 2, 0, 0, 0, 0, 2, 3, 0, 2, 3, 0, 2, 0, 2, 2, 2,\n",
            "       0, 1, 2, 0, 3, 2, 2, 0, 2, 2, 2, 0, 3, 2, 0, 0, 2, 1, 3, 1, 2, 0,\n",
            "       3, 0, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 3, 0, 0, 3, 3, 3, 1, 2,\n",
            "       0, 2, 0, 2, 3, 2, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 2,\n",
            "       0, 3, 3, 0, 2, 0, 3, 0, 0, 0, 0, 0, 2, 3, 2, 2, 2, 2, 0, 2, 0, 3,\n",
            "       3, 0, 0, 3, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0,\n",
            "       3, 2, 2, 0, 3, 0, 0, 2, 2, 0, 1, 2, 3, 0, 0, 3, 0, 0, 0, 2, 3, 2,\n",
            "       0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 3, 2, 0, 3, 3, 0, 3,\n",
            "       3, 0, 2, 0, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 3, 2,\n",
            "       0, 2, 0, 0, 3, 2, 0, 2, 2, 3, 0, 0, 0, 3, 0, 0, 2, 2, 0, 3, 0, 2,\n",
            "       2, 0, 0, 0, 0, 2, 3, 0, 3, 0, 3, 2, 3, 3, 0, 2, 2, 2, 0, 3, 2, 0,\n",
            "       2, 2, 1, 1, 1, 0, 3, 0, 3, 3, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2,\n",
            "       2, 2, 0, 2, 1, 0, 0, 3, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0, 3, 0, 2, 0,\n",
            "       3, 1, 3, 2, 0, 2, 3, 1, 0, 3, 0, 0, 0, 0, 0, 3, 2, 0, 0, 3, 0, 3,\n",
            "       2, 0, 3, 0, 2, 0, 3, 3, 0, 2, 0, 2, 0, 1, 0, 3, 2, 0, 2, 2, 2, 0,\n",
            "       0, 0, 0, 0, 2, 0, 3, 0, 3, 2, 3, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1,\n",
            "       0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 2, 3, 0, 3, 2, 2, 2, 0, 0, 0, 2,\n",
            "       0, 2, 2, 2, 2, 2, 3, 0, 0, 0, 3, 3, 2, 2, 2, 0, 0, 2, 0, 2, 3, 0,\n",
            "       0, 0, 0, 0, 1, 3, 2, 2, 1, 3, 3, 0, 0, 2, 1, 2, 3, 0, 2, 3, 2, 0,\n",
            "       3, 3, 0, 0, 2, 0, 0, 3, 3, 0, 2, 3, 2, 0, 0, 0, 3, 3, 0, 2, 0, 2,\n",
            "       3, 0, 3, 0, 0, 2, 3, 2]), 'svm_rbf': array([0, 0, 2, 0, 0, 3, 0, 2, 2, 0, 0, 3, 2, 2, 2, 0, 2, 2, 0, 0, 3, 2,\n",
            "       0, 2, 3, 0, 0, 2, 2, 0, 0, 0, 2, 0, 3, 0, 0, 0, 0, 0, 0, 2, 3, 2,\n",
            "       2, 2, 0, 0, 3, 0, 0, 0, 2, 0, 2, 0, 0, 0, 3, 0, 2, 0, 2, 3, 0, 2,\n",
            "       0, 0, 3, 0, 3, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0,\n",
            "       3, 2, 0, 3, 0, 2, 3, 2, 3, 2, 3, 2, 2, 0, 2, 0, 2, 3, 0, 0, 3, 0,\n",
            "       0, 2, 3, 0, 3, 2, 0, 0, 2, 3, 3, 0, 2, 2, 2, 2, 2, 0, 0, 3, 2, 0,\n",
            "       3, 2, 3, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2, 0, 3, 2, 0, 0, 3, 2, 2, 2,\n",
            "       0, 0, 3, 0, 0, 2, 2, 3, 0, 0, 0, 3, 0, 2, 2, 3, 2, 2, 2, 0, 2, 0,\n",
            "       0, 0, 2, 3, 0, 2, 3, 0, 0, 2, 3, 0, 2, 2, 3, 3, 0, 3, 2, 0, 2, 0,\n",
            "       2, 2, 3, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
            "       0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 3, 2, 3, 2, 0, 2, 2, 2, 0,\n",
            "       0, 3, 2, 2, 2, 0, 0, 0, 2, 0, 3, 0, 2, 2, 2, 0, 0, 0, 2, 0, 2, 0,\n",
            "       3, 0, 0, 0, 0, 0, 0, 3, 3, 2, 0, 2, 0, 2, 2, 2, 0, 3, 2, 0, 0, 0,\n",
            "       2, 0, 2, 0, 3, 2, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0,\n",
            "       2, 3, 2, 0, 0, 0, 0, 3, 2, 2, 2, 0, 2, 3, 0, 0, 0, 0, 0, 0, 3, 0,\n",
            "       0, 0, 0, 0, 3, 2, 0, 0, 2, 3, 3, 0, 3, 0, 3, 0, 0, 0, 0, 2, 0, 3,\n",
            "       2, 0, 3, 0, 0, 0, 2, 0, 0, 0, 0, 2, 3, 0, 2, 3, 0, 2, 0, 2, 2, 2,\n",
            "       0, 0, 2, 0, 3, 2, 2, 0, 2, 2, 2, 0, 3, 2, 0, 0, 2, 0, 3, 0, 2, 0,\n",
            "       3, 0, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 3, 0, 0, 3, 2, 3, 0, 2,\n",
            "       0, 2, 0, 2, 3, 2, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2,\n",
            "       0, 3, 3, 0, 2, 0, 3, 0, 0, 0, 0, 0, 2, 3, 2, 2, 2, 2, 0, 2, 0, 3,\n",
            "       3, 0, 0, 3, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0,\n",
            "       3, 2, 2, 0, 3, 0, 0, 2, 2, 0, 2, 2, 3, 0, 0, 3, 0, 0, 0, 2, 3, 2,\n",
            "       0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 3, 2, 0, 3, 3, 0, 3,\n",
            "       3, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 3, 2,\n",
            "       0, 2, 0, 0, 3, 2, 0, 2, 2, 2, 0, 0, 0, 3, 0, 0, 2, 2, 0, 3, 0, 2,\n",
            "       2, 0, 0, 0, 0, 2, 3, 0, 3, 0, 3, 2, 3, 3, 0, 2, 2, 2, 0, 3, 2, 0,\n",
            "       2, 2, 0, 2, 0, 0, 2, 0, 3, 3, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2,\n",
            "       2, 2, 0, 2, 2, 0, 0, 3, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0, 3, 0, 2, 0,\n",
            "       3, 0, 3, 2, 0, 2, 3, 0, 0, 3, 0, 0, 0, 0, 0, 3, 2, 0, 0, 3, 0, 2,\n",
            "       2, 0, 3, 0, 2, 0, 3, 3, 0, 2, 0, 2, 0, 0, 0, 3, 2, 0, 2, 2, 2, 0,\n",
            "       0, 0, 0, 0, 2, 0, 3, 0, 3, 2, 3, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
            "       0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 2, 3, 0, 3, 2, 2, 2, 0, 0, 0, 2,\n",
            "       0, 2, 2, 2, 2, 2, 3, 0, 0, 0, 3, 3, 2, 2, 2, 0, 0, 2, 0, 2, 3, 0,\n",
            "       0, 0, 0, 0, 0, 3, 2, 2, 0, 3, 3, 0, 0, 2, 0, 2, 3, 0, 2, 3, 2, 0,\n",
            "       3, 3, 0, 0, 2, 0, 0, 3, 2, 0, 2, 2, 2, 0, 0, 0, 2, 3, 0, 2, 0, 2,\n",
            "       3, 0, 3, 0, 0, 2, 3, 2])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(model):\n",
        "  pred_Y = model.predict(X_test)\n",
        "  acc = metrics.accuracy_score(y_test, pred_Y)\n",
        "  precision = metrics.precision_score(y_test, pred_Y)\n",
        "  recall = metrics.recall_score(y_test, pred_Y)\n",
        "  f1_score = metrics.f1_score(y_test, pred_Y)\n",
        "  rmse = np.sqrt(metrics.mean_squared_error(y_test, pred_Y))\n",
        "  return [acc, precision, recall, f1_score, rmse]\n",
        "\n",
        "# table = pd.DataFrame()\n",
        "# table[\"Metric\"] = [\"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"RMSE\"]\n",
        "# table[\"Linear - Fold 2\"] = get_metrics(best_linear)\n",
        "# table[\"Poly - Fold 2\"] = get_metrics(best_poly)\n",
        "# table[\"RBF - Fold 2\"] = get_metrics(best_rbf)\n",
        "\n",
        "# table.head()"
      ],
      "metadata": {
        "id": "7-wRvWY7mvJ4"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}