{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aimbesi1/CSC_4850-MachineLearning-Project/blob/main/ML_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PjGD5VGFVS-s"
      },
      "outputs": [],
      "source": [
        "# Default imports\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "# Specific imports\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the housing dataset from Kaggle: https://www.kaggle.com/datasets/mirbektoktogaraev/madrid-real-estate-market"
      ],
      "metadata": {
        "id": "89_ilQegV-MS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Manually download it and upload to this istance data sample space\n",
        "### Note DO NOT change these operations or all your answers will be incorrect\n",
        "\n",
        "### Let's do some transformations and extra features on this.\n",
        "df=pd.read_csv('houses_Madrid.csv', encoding='utf-8')"
      ],
      "metadata": {
        "id": "J_sakm7HV90A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select/clean features here\n",
        "\n",
        "# Do what needs to be done to the data so that the models can run"
      ],
      "metadata": {
        "id": "cQxCC0sziHIa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update X values later\n",
        "df_short = df.iloc[:1000, :][['sq_mt_built', 'rent_price', 'buy_price']].dropna()\n",
        "df_short['high_price'] = df_short['buy_price'].apply(lambda x: 1 if x > np.median(df_short['buy_price']) else 0)\n",
        "X = df_short[['sq_mt_built', 'rent_price']]\n",
        "# y = df_short[['buy_price']]\n",
        "y = df_short['high_price'].values\n",
        "\n"
      ],
      "metadata": {
        "id": "mv3OV1HJE4VZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "def init_models():\n",
        "  dt = DecisionTreeRegressor(random_state=1234)\n",
        "  perceptron = Perceptron(random_state=1234)\n",
        "  nb = GaussianNB()\n",
        "  log_reg = LogisticRegression(random_state=1234)\n",
        "  lin_reg = LinearRegression()\n",
        "  ridge = Ridge(alpha=0.5, fit_intercept=True, random_state=1234)\n",
        "  lasso = Lasso(alpha=0.1, fit_intercept=True, random_state=1234)\n",
        "  ef = ElasticNet(alpha=0.9, fit_intercept=True, random_state=1234)\n",
        "  svm_linear = svm.SVC(kernel=\"linear\", random_state=1234)\n",
        "  svm_rbf = svm.SVC(kernel=\"rbf\", random_state=1234)\n",
        "  gbr = GradientBoostingRegressor(random_state=1234)\n",
        "  mlp = MLPRegressor(random_state=1234)\n",
        "  svr_poly = svm.SVR(kernel=\"poly\")\n",
        "\n",
        "  dict = {\n",
        "      \"dt\": dt,\n",
        "      \"perceptron\": perceptron,\n",
        "      \"nb\": nb,\n",
        "      \"log_reg\": log_reg,\n",
        "      \"lin_reg\": lin_reg,\n",
        "      \"ridge\": ridge,\n",
        "      \"lasso\": lasso,\n",
        "      \"ef\": ef,\n",
        "      \"svm_linear\": svm_linear,\n",
        "      \"svm_rbf\": svm_rbf,\n",
        "      \"gbr\": gbr,\n",
        "      \"mlp\": mlp,\n",
        "  }\n",
        "\n",
        "  return dict"
      ],
      "metadata": {
        "id": "vp82oe_ux2xM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_models(models, X_train, X_test, y_train, y_test, lc_dict, m_dict, b_dict):\n",
        "  def get_metrics(model, X_train, y_train):\n",
        "    # lc = learning_curve(estimator=model, X=X_train, y=y_train, cv=10, shuffle=True, random_state=1234)\n",
        "    lc = -1\n",
        "    cv = cross_validate(model, X_train, y_train, cv=10, scoring=(\"precision\", \"recall\", \"accuracy\", \"f1\"), return_train_score=False, return_estimator=True)\n",
        "    best_score_index = cv[\"test_accuracy\"].argmax()\n",
        "    best = cv[\"estimator\"][best_score_index]\n",
        "    return lc, cv, best\n",
        "\n",
        "\n",
        "  for key in models.keys():\n",
        "    lc, cv, best = None, None, None\n",
        "    if key in {\"svm_lin\", \"lin_reg\", \"ridge\", \"lasso\", \"ef\"}:\n",
        "      X_train_scaled = StandardScaler().fit_transform(X_train)\n",
        "      X_test_scaled = StandardScaler().fit_transform(X_test)\n",
        "\n",
        "      models[key].fit(X_train_scaled, y_train)\n",
        "      predY = models[key].predict(X_test_scaled)\n",
        "      lc, cv, best = get_metrics(models[key], X_train_scaled, y_train)\n",
        "    else:\n",
        "      models[key].fit(X_train, y_train)\n",
        "      predY = models[key].predict(X_test)\n",
        "      lc, cv, best = get_metrics(models[key], X_train, y_train)\n",
        "    \n",
        "    # lc_dict[key] = lc\n",
        "    m_dict[key] = cv\n",
        "    b_dict[key] = best\n",
        "\n",
        "def test_models(models, X_train, X_test, y_train, y_test, lc_dict, bp_dict):\n",
        "  for key in models.keys():\n",
        "    lc, predY = None, None\n",
        "    if key in {\"svm_lin\", \"lin_reg\", \"ridge\", \"lasso\", \"ef\"}:\n",
        "      X_train_scaled = StandardScaler().fit_transform(X_train)\n",
        "      X_test_scaled = StandardScaler().fit_transform(X_test)\n",
        "\n",
        "      models[key].fit(X_train_scaled, y_train)\n",
        "      predY = models[key].predict(X_test_scaled)\n",
        "      lc = learning_curve(estimator=models[key], X=X_test_scaled, y=y_test, shuffle=True, random_state=1234)\n",
        "    else:\n",
        "      models[key].fit(X_train, y_train)\n",
        "      predY = models[key].predict(X_test)\n",
        "      lc = learning_curve(estimator=models[key], X=X_test, y=y_test, shuffle=True, random_state=1234)\n",
        "\n",
        "    lc_dict[key] = lc\n",
        "    bp_dict[key] = predY\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "# def run_models(models, X_train, y_train, X_test, y_test):\n",
        "\n",
        "#   # Decision Tree\n",
        "#   models[\"dt\"].fit(X_train, y_train)\n",
        "#   pred_Y1 = models[\"dt\"].predict(X_test)\n",
        "#   print(metrics.classification_report(y_test, pred_Y1))\n",
        "\n",
        "#   # SVM Linear\n",
        "#   f1_scaledX = StandardScaler().fit(X_train).transform(X_train)\n",
        "#   f1_scaledX_test = StandardScaler().fit(X_test).transform(X_test)\n",
        "\n",
        "#   models[\"svm_linear\"].fit(f1_scaledX, y_train)\n",
        "#   pred_Y1 = models[\"svm_linear\"].predict(f1_scaledX_test)\n",
        "#   print(metrics.classification_report(y_test, pred_Y1))\n",
        "\n",
        "#   sizes1, train_scores1, valid_scores1 = learning_curve(estimator = svm_linear, X = f1_scaledX_test, y=y_test, shuffle = True, random_state = 1234)\n",
        "\n",
        "#   # RBF\n",
        "#   models[\"svm_rbf\"].fit(X_train, y_train)\n",
        "#   pred_Y3 = models[\"svm_rbf\"].predict(X_test)\n",
        "#   print(metrics.classification_report(y_test, pred_Y3))\n",
        "\n",
        "#   sizes3, train_scores3, valid_scores3 = learning_curve(estimator = svm_rbf, X = X_test, y=y_test, shuffle = True, random_state = 1234)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "def show_learning_curve(ax, lc_sizes, train_scores, valid_scores, title):\n",
        "  train_mean = train_scores.mean(axis=1)\n",
        "  valid_mean = valid_scores.mean(axis=0)\n",
        "  ax.plot(lc_sizes, train_mean, label = \"Training Error - Sample 1\")\n",
        "  ax.plot(lc_sizes, valid_mean, label = \"Validation Error - Sample 1\")\n",
        "  ax.legend()\n",
        "  ax.set_title(title)\n",
        "\n",
        "\n",
        "# # Learning curves\n",
        "# f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (15, 5), sharey=True)\n",
        "# show_learning_curve(ax1, sizes1, train_scores1, valid_scores1, \"Linear\")\n",
        "# show_learning_curve(ax2, sizes2, train_scores2, valid_scores2, \"Poly\")\n",
        "# show_learning_curve(ax3, sizes3, train_scores3, valid_scores3, \"RBF\")\n",
        "\n",
        "# acc_linear = metrics.accuracy_score(fold[\"y_test\"], pred_Y1)\n",
        "# acc_poly = metrics.accuracy_score(fold[\"y_test\"], pred_Y2)\n",
        "# acc_rbf = metrics.accuracy_score(fold[\"y_test\"], pred_Y3)\n",
        "# return {\"linear\": svm_linear, \"poly\": svm_poly, \"rbf\": svm_rbf}\n",
        "\n",
        "# f1_results = run_models(fold1, svm_linear, svm_poly, svm_rbf)"
      ],
      "metadata": {
        "id": "OlQED2C0kSQ-"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Pipeline\n",
        "\n",
        "''' \n",
        "For each sampling:\n",
        "  Set up the models\n",
        "  Initialize L: list of LCs (list of training scores + valid scores)\n",
        "  Initialize M: list of metrics (predicted Y)\n",
        "  \n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "def pipe(X, y):\n",
        "  train_sizes = [0.50, 0.70, 0.80]\n",
        "  # learning_curves and metrics are arrays of 3 dictionaries each.\n",
        "  # Each dictionary will hold the learning curve and metrics data for each model in each fold. \n",
        "  learning_curves = np.array([{}, {}, {}])\n",
        "  metrics = np.array([{}, {}, {}])\n",
        "  models = {}\n",
        "  best_models = np.array([{}, {}, {}])\n",
        "  best_predictions = np.array([{}, {}, {}])\n",
        "\n",
        "  for i in range(len(train_sizes)):\n",
        "    models = init_models()\n",
        "    rbf = {\"rbf\": models[\"svm_rbf\"]}\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_sizes[i], random_state=1234)\n",
        "\n",
        "    # Test with 1 model\n",
        "    run_models(rbf, X_train, X_test, y_train, y_test, learning_curves[i], metrics[i], best_models[i])\n",
        "    \n",
        "    \n",
        "    # print(learning_curves[i])\n",
        "    \n",
        "    print(metrics[i])\n",
        "\n",
        "    print(best_models[i])\n",
        "\n",
        "    # Stop at 1 loop with break\n",
        "    # break\n",
        "\n",
        "    # Now train the best models on the whole training set\n",
        "    \n",
        "    test_models(rbf, X_train, X_test, y_train, y_test, learning_curves[i], best_predictions[i])\n",
        "\n",
        "\n",
        "  \n",
        "  # Learning curves\n",
        "  f, ax = plt.subplots(1, len(models), figsize = (15, 5), sharey=True)\n",
        "  \n",
        "  for i in range(len(models)):\n",
        "    \n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "# def pipe(X, y):\n",
        "#   train_sizes = [0.50, 0.70, 0.80]\n",
        "#   for size in train_sizes:\n",
        "#     models = init_models()\n",
        "#     rbf = models[\"svm_rbf\"]\n",
        "#     X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=size, random_state=1234)\n",
        "\n",
        "#     kfold = KFold(n_splits=10, random_state=1234, shuffle=True)\n",
        "\n",
        "#     for index, (train, test) in enumerate(kfold.split(X_train,y_train)):\n",
        "#       X_train_folds = X_train[train]\n",
        "#       y_train_folds = y_train[train]\n",
        "\n",
        "#       X_test_folds = X_train[test]\n",
        "#       y_test_folds = y_train[test]\n",
        "\n",
        "#       run_models(models, X_train_folds, y_train_folds, X_test_folds, y_test_folds)\n",
        "\n",
        "pipe(X, y)"
      ],
      "metadata": {
        "id": "OVEa6yRHpsVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a515544-05a6-4024-ad0d-9d5bd4b8f9e5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rbf': {'fit_time': array([0.00369096, 0.00281453, 0.00386024, 0.00286913, 0.0027194 ,\n",
            "       0.00304985, 0.00322318, 0.00277352, 0.00333881, 0.00289774]), 'score_time': array([0.00470757, 0.00449228, 0.00494075, 0.0043242 , 0.00432658,\n",
            "       0.00541663, 0.00431514, 0.00580645, 0.00430274, 0.00419831]), 'estimator': [SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234)], 'test_precision': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_recall': array([1.        , 0.95833333, 1.        , 0.95833333, 0.95833333,\n",
            "       1.        , 0.91666667, 0.91666667, 1.        , 1.        ]), 'test_accuracy': array([1.  , 0.98, 1.  , 0.98, 0.98, 1.  , 0.96, 0.96, 1.  , 1.  ]), 'test_f1': array([1.        , 0.9787234 , 1.        , 0.9787234 , 0.9787234 ,\n",
            "       1.        , 0.95652174, 0.95652174, 1.        , 1.        ])}}\n",
            "{'rbf': SVC(random_state=1234)}\n",
            "{'rbf': {'fit_time': array([0.0034492 , 0.00602078, 0.006495  , 0.00381899, 0.00382137,\n",
            "       0.00368643, 0.0038259 , 0.0034883 , 0.00358057, 0.00352478]), 'score_time': array([0.00753689, 0.00462985, 0.00531125, 0.00493431, 0.0046165 ,\n",
            "       0.00441074, 0.00470281, 0.00541353, 0.0052278 , 0.00433779]), 'estimator': [SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234)], 'test_precision': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_recall': array([0.93939394, 0.96969697, 0.91176471, 1.        , 1.        ,\n",
            "       0.97058824, 0.97058824, 0.97058824, 0.94117647, 1.        ]), 'test_accuracy': array([0.97142857, 0.98571429, 0.95714286, 1.        , 1.        ,\n",
            "       0.98571429, 0.98571429, 0.98571429, 0.97142857, 1.        ]), 'test_f1': array([0.96875   , 0.98461538, 0.95384615, 1.        , 1.        ,\n",
            "       0.98507463, 0.98507463, 0.98507463, 0.96969697, 1.        ])}}\n",
            "{'rbf': SVC(random_state=1234)}\n",
            "{'rbf': {'fit_time': array([0.00394344, 0.00386   , 0.00391269, 0.00379109, 0.00523472,\n",
            "       0.00403428, 0.0043726 , 0.00440502, 0.0038271 , 0.00387454]), 'score_time': array([0.0051043 , 0.00448632, 0.00444031, 0.00439692, 0.00467181,\n",
            "       0.00445104, 0.00642848, 0.00443149, 0.0043776 , 0.00433087]), 'estimator': [SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234), SVC(random_state=1234)], 'test_precision': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'test_recall': array([0.97368421, 0.94871795, 1.        , 0.92307692, 1.        ,\n",
            "       1.        , 0.94871795, 0.97435897, 0.94871795, 1.        ]), 'test_accuracy': array([0.9875, 0.975 , 1.    , 0.9625, 1.    , 1.    , 0.975 , 0.9875,\n",
            "       0.975 , 1.    ]), 'test_f1': array([0.98666667, 0.97368421, 1.        , 0.96      , 1.        ,\n",
            "       1.        , 0.97368421, 0.98701299, 0.97368421, 1.        ])}}\n",
            "{'rbf': SVC(random_state=1234)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(model):\n",
        "  pred_Y = model.predict(X_test)\n",
        "  acc = metrics.accuracy_score(y_test, pred_Y)\n",
        "  precision = metrics.precision_score(y_test, pred_Y)\n",
        "  recall = metrics.recall_score(y_test, pred_Y)\n",
        "  f1_score = metrics.f1_score(y_test, pred_Y)\n",
        "  rmse = np.sqrt(metrics.mean_squared_error(y_test, pred_Y))\n",
        "  return [acc, precision, recall, f1_score, rmse]\n",
        "\n",
        "# table = pd.DataFrame()\n",
        "# table[\"Metric\"] = [\"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"RMSE\"]\n",
        "# table[\"Linear - Fold 2\"] = get_metrics(best_linear)\n",
        "# table[\"Poly - Fold 2\"] = get_metrics(best_poly)\n",
        "# table[\"RBF - Fold 2\"] = get_metrics(best_rbf)\n",
        "\n",
        "# table.head()"
      ],
      "metadata": {
        "id": "7-wRvWY7mvJ4"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}